{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tweepy as tw\n",
    "import json\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import LFApplier\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sqlite3\n",
    "\n",
    "ABSTAIN = -1\n",
    "NEGATIVE = 0\n",
    "POSITIVE = 1\n",
    "\n",
    "#Common names that have been found in dataset\n",
    "l_names_or_places = r\"(van dyke|ponce de leon|ponce city|ponce inlet town)\" \n",
    "@labeling_function()\n",
    "def names_or_places(tweet):\n",
    "    return NEGATIVE if re.search(l_names_or_places, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Common simple insults\n",
    "l_simple_insults = r\"(fucking|disgusting|ugly|bitchy|pathetic) (fag|faggot|fags|fudgepacker|fudge packer|poofter|pansy|bender|batty boy|ponce|dyke|rug muncher|lesbo|tranny|trannie|transvestite|ladyboy|heshe|shemale|switch hitter)\"\n",
    "@labeling_function()\n",
    "def simple_insults(tweet):\n",
    "    return POSITIVE if re.search(l_simple_insults, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Common terms used to identify the subject of a given bad term e.g. \"You ***\" \n",
    "l_term_to_person = r\"(that|this|you|shut the fuck up|stfu|shut up) (fag|faggot|fags|fudgepacker|fudge packer|poofter|pansy|bender|batty boy|ponce|dyke|rug muncher|lesbo|tranny|trannie|transvestite|ladyboy|heshe|shemale|switch hitter)\"\n",
    "@labeling_function()\n",
    "def term_to_person(tweet):\n",
    "    return POSITIVE if re.search(l_term_to_person, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Using term in a descriptive yet derogatory manner\n",
    "l_descriptive_bad = r\"(piece of|like a|being a|kind of a?) (fag|faggot|fags|fudgepacker|fudge packer|poofter|pansy|bender|batty boy|ponce|dyke|rug muncher|lesbo|tranny|trannie|transvestite|ladyboy|heshe|shemale|switch hitter)\"\n",
    "@labeling_function()\n",
    "def descriptive_bad(tweet):\n",
    "    return POSITIVE if re.search(l_descriptive_bad, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Stating someone on the LGBT spectrum is unnatural\n",
    "l_against_nature = r\"(against|defying) (god|biology|nature)\"\n",
    "@labeling_function()\n",
    "def against_nature(tweet):\n",
    "    return POSITIVE if re.search(l_against_nature, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Term is used in full caps\n",
    "l_bad_words_caps = r\"(FAGS?|FAGGOTS?|FUDGE ?PACKERS?|POOFTERS?|PANSY|PANSIES|BENDERS?|BATTY BOYS?|PONCE|DYKES?|RUG ?MUNCHERS?|LESBOS?|TRANNY|TRANNIES?|TRANSVESTITES?|LADYBOYS?|HESHES?|SHE ?MALES?|SWITCH ?-?HITTERS?)\"\n",
    "@labeling_function()\n",
    "def full_caps(tweet):\n",
    "    return POSITIVE if re.search(l_bad_words, tweet.TWEET) else ABSTAIN\n",
    "\n",
    "#Contains trigger warning\n",
    "l_trigger_warnings = r\"(\\/+ *tw|\\/* *trigger warning|tw *\\/+)\"\n",
    "@labeling_function()\n",
    "def trigger_warning(tweet):\n",
    "    return NEGATIVE if re.search(l_trigger_warnings, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Using term 'Bender' when talking about drunken stints\n",
    "l_bender_as_drunk = r\"(day|on a) bender\"\n",
    "@labeling_function()\n",
    "def bender_as_drunk(tweet):\n",
    "    return NEGATIVE if re.search(l_bender_as_drunk, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Using Bender as a pop culture reference e.g. avatar the last airbender or Futurama reference\n",
    "l_bender_pop_culture = r\"((fender|water|earth|fire|wind|energy) *bender)|futurama.*bender|bender.*futurama|avatar.*bender\"\n",
    "@labeling_function()\n",
    "def bender_pop_culture(tweet):\n",
    "    return NEGATIVE if re.search(l_bender_pop_culture, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Using slang term for using cigarettes\n",
    "l_slang_using_cigarettes = r\"((for|smoke|have|smoking|having|want) (some|a) fags?)|fag ash\"\n",
    "@labeling_function()\n",
    "def slang_using_cigarettes(tweet):\n",
    "    return NEGATIVE if re.search(l_slang_using_cigarettes, tweet.TWEET.lower()) else ABSTAIN\n",
    "\n",
    "#Slur is part of a mentioned twitter handle\n",
    "l_handles = r\"(\\@[a-z0-9_]*)\"\n",
    "@labeling_function()\n",
    "def slur_in_handles(tweet):\n",
    "    in_handle = 0\n",
    "    bad_terms = ['fag', 'faggot', 'fags', 'fudgepacker', 'fudge+packer', 'poofter', 'pansy', 'bender', 'batty+boy', 'ponce', 'dyke', 'rug+muncher', 'lesbo','tranny', 'trannie', 'transvestite', 'ladyboy', 'heshe', 'shemale','switch+hitter', 'gay+for+pay']\n",
    "    #check for slur in handle\n",
    "    handles = re.findall(l_handles, tweet.TWEET.lower())\n",
    "    for handle in handles:\n",
    "        if any(substring in handle for substring in bad_terms):\n",
    "            in_handle+=1\n",
    "    return NEGATIVE if in_handle>0 else ABSTAIN\n",
    "\n",
    "#User has pronouns in bio\n",
    "@labeling_function()\n",
    "def has_pronouns(tweet):\n",
    "    return NEGATIVE if tweet.HASPRONOUNS==1 else ABSTAIN\n",
    "\n",
    "def make_Ls_matrix(data, LFs):\n",
    "    noisy_labels = np.empty((len(data), len(LFs)))\n",
    "    for i, row in data.iterrows():\n",
    "        for j, lf in enumerate(LFs):\n",
    "            noisy_labels[i][j] = lf(row)\n",
    "    return noisy_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate labelling functions\n",
    "lfs = [names_or_places,simple_insults,term_to_person,descriptive_bad,against_nature,trigger_warning,bender_as_drunk,bender_pop_culture,slang_using_cigarettes,slur_in_handles,has_pronouns]\n",
    "applier = LFApplier(lfs=lfs)\n",
    "pdapplier = PandasLFApplier(lfs=lfs)\n",
    "#Update Pandas Dataframe so that displayed dataframes are not truncated\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "#Connect to DB\n",
    "conn = sqlite3.connect(\"tweets.db\")\n",
    "#Retrieve Tweets from Database\n",
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "    #Construct SQL Queries\n",
    "    #Obtain all manually labelled tweets from DB\n",
    "    pd_data = pd.read_sql(con=conn,sql=\"SELECT * FROM TWEETS WHERE ISHARASSMENT IS NOT NULL\")\n",
    "#Create train test split\n",
    "df_train, df_test = train_test_split(pd_data, test_size=0.33, random_state=42)\n",
    "Y_test = df_test.ISHARASSMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.snorkel.org/use-cases/01-spam-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:00<00:00, 5901.13it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1,  0, -1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage names or places: 6.14035087719298%\n",
      "coverage simple insults: 1.16959064327485%\n",
      "coverage term to person: 2.04678362573099%\n",
      "coverage descriptive bad term: 1.46198830409357%\n",
      "coverage against nature: 0.29239766081871%\n",
      "coverage trigger warning: 0.58479532163743%\n",
      "coverage bender as drunk: 0.58479532163743%\n",
      "coverage bender in pop culture: 1.75438596491228%\n",
      "coverage slang using cigarettes: 1.16959064327485%\n",
      "coverage slur in handles: 16.95906432748538%\n",
      "coverage has pronouns in bio: 10.23391812865497%\n"
     ]
    }
   ],
   "source": [
    "coverage_names_or_places, coverage_simple_insults,coverage_term_to_person,coverage_descriptive_bad,coverage_against_nature,coverage_trigger_warning,coverage_bender_as_drunk,coverage_bender_pop_culture,coverage_slang_using_cigarettes,coverage_slur_in_handles,coverage_has_pronouns = (L_train!=ABSTAIN).mean(axis=0)\n",
    "print(f\"coverage names or places: { coverage_names_or_places * 100:.14f}%\")\n",
    "print(f\"coverage simple insults: { coverage_simple_insults * 100:.14f}%\")\n",
    "print(f\"coverage term to person: { coverage_term_to_person * 100:.14f}%\")\n",
    "print(f\"coverage descriptive bad term: { coverage_descriptive_bad * 100:.14f}%\")\n",
    "print(f\"coverage against nature: { coverage_against_nature * 100:.14f}%\")\n",
    "print(f\"coverage trigger warning: { coverage_trigger_warning * 100:.14f}%\")\n",
    "print(f\"coverage bender as drunk: { coverage_bender_as_drunk * 100:.14f}%\")\n",
    "print(f\"coverage bender in pop culture: { coverage_bender_pop_culture * 100:.14f}%\")\n",
    "print(f\"coverage slang using cigarettes: { coverage_slang_using_cigarettes * 100:.14f}%\")\n",
    "print(f\"coverage slur in handles: { coverage_slur_in_handles * 100:.14f}%\")\n",
    "print(f\"coverage has pronouns in bio: { coverage_has_pronouns* 100:.14f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>names_or_places</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_insults</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_to_person</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descriptive_bad</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>against_nature</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigger_warning</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bender_as_drunk</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bender_pop_culture</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_using_cigarettes</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slur_in_handles</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.169591</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_pronouns</th>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j Polarity  Coverage  Overlaps  Conflicts\n",
       "names_or_places         0   [0]      0.061404  0.002924  0.000000 \n",
       "simple_insults          1   [1]      0.011696  0.000000  0.000000 \n",
       "term_to_person          2   [1]      0.020468  0.002924  0.002924 \n",
       "descriptive_bad         3   [1]      0.014620  0.000000  0.000000 \n",
       "against_nature          4   [1]      0.002924  0.000000  0.000000 \n",
       "trigger_warning         5   [0]      0.005848  0.000000  0.000000 \n",
       "bender_as_drunk         6   [0]      0.005848  0.000000  0.000000 \n",
       "bender_pop_culture      7   [0]      0.017544  0.002924  0.000000 \n",
       "slang_using_cigarettes  8   [0]      0.011696  0.002924  0.000000 \n",
       "slur_in_handles         9   [0]      0.169591  0.029240  0.000000 \n",
       "has_pronouns            10  [0]      0.102339  0.040936  0.002924 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>ISTYPEHOMOSEXUAL</th>\n",
       "      <th>ISTYPETRANSGENDER</th>\n",
       "      <th>ISTYPEBISEXUAL</th>\n",
       "      <th>HASPRONOUNS</th>\n",
       "      <th>ISHARASSMENT</th>\n",
       "      <th>AUTO_ISHARASSMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1371969703027953666</td>\n",
       "      <td>1227977888860798982</td>\n",
       "      <td>This man Will Barton is 6'5 wearing super skinnie jeans with his knee out. Idc about this fags ego the Nuggets need to start MPJ police loving ass</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1371970229010534401</td>\n",
       "      <td>1111839485874995200</td>\n",
       "      <td>@horansarizona stfu dyke</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1372542942087364609</td>\n",
       "      <td>1050750048475209730</td>\n",
       "      <td>i remember I was dating this dyke who constantly tweeted about how much she liked big booty girls with tiny waists but could not begin to understand why I felt so offended by it. this is the reason right here, because I’m clearly not your type https://t.co/KP8LqVIgOM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1371949548021690377</td>\n",
       "      <td>1358657061467222018</td>\n",
       "      <td>TG: shut up karkat\\nTG: you fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1371242299519303681</td>\n",
       "      <td>1342695061151166472</td>\n",
       "      <td>Gibbs said \"I'll never let this industry demasculinize me\" with all this batty boy shit going on in the industry he never had a chance...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1365280595081797633</td>\n",
       "      <td>1195598451729321984</td>\n",
       "      <td>@schizoidfemdog That faggot is so annoying and hot God</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1371955536619433985</td>\n",
       "      <td>1237100903347269639</td>\n",
       "      <td>@MrsLadyValkyrie @glowingcanary @CompelLearning @hondo64ou1 @back2monke @LindseyBoylan I probably know more than you pansy ass ever will.  I am very knowledgeable  that's why I can take the stance I do. From knowledge and experience. And I know bull shit when I see it.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TWEETID               USERID  \\\n",
       "466  1371969703027953666  1227977888860798982   \n",
       "464  1371970229010534401  1111839485874995200   \n",
       "198  1372542942087364609  1050750048475209730   \n",
       "499  1371949548021690377  1358657061467222018   \n",
       "353  1371242299519303681  1342695061151166472   \n",
       "149  1365280595081797633  1195598451729321984   \n",
       "484  1371955536619433985  1237100903347269639   \n",
       "\n",
       "                                                                                                                                                                                                                                                                             TWEET  \\\n",
       "466  This man Will Barton is 6'5 wearing super skinnie jeans with his knee out. Idc about this fags ego the Nuggets need to start MPJ police loving ass                                                                                                                              \n",
       "464  @horansarizona stfu dyke                                                                                                                                                                                                                                                        \n",
       "198  i remember I was dating this dyke who constantly tweeted about how much she liked big booty girls with tiny waists but could not begin to understand why I felt so offended by it. this is the reason right here, because I’m clearly not your type https://t.co/KP8LqVIgOM     \n",
       "499  TG: shut up karkat\\nTG: you fag                                                                                                                                                                                                                                                 \n",
       "353  Gibbs said \"I'll never let this industry demasculinize me\" with all this batty boy shit going on in the industry he never had a chance...                                                                                                                                       \n",
       "149  @schizoidfemdog That faggot is so annoying and hot God                                                                                                                                                                                                                          \n",
       "484  @MrsLadyValkyrie @glowingcanary @CompelLearning @hondo64ou1 @back2monke @LindseyBoylan I probably know more than you pansy ass ever will.  I am very knowledgeable  that's why I can take the stance I do. From knowledge and experience. And I know bull shit when I see it.   \n",
       "\n",
       "     ISTYPEHOMOSEXUAL  ISTYPETRANSGENDER  ISTYPEBISEXUAL  HASPRONOUNS  \\\n",
       "466  1                 0                  0               0.0           \n",
       "464  1                 0                  0               1.0           \n",
       "198  1                 0                  0               0.0           \n",
       "499  1                 0                  0               0.0           \n",
       "353  0                 0                  0               0.0           \n",
       "149  1                 0                  0               0.0           \n",
       "484  1                 0                  0               0.0           \n",
       "\n",
       "     ISHARASSMENT AUTO_ISHARASSMENT  \n",
       "466  1             None              \n",
       "464  1             None              \n",
       "198  1             None              \n",
       "499  1             None              \n",
       "353  1             None              \n",
       "149  1             None              \n",
       "484  1             None              "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[L_train[:,2] == POSITIVE].sample(7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>ISTYPEHOMOSEXUAL</th>\n",
       "      <th>ISTYPETRANSGENDER</th>\n",
       "      <th>ISTYPEBISEXUAL</th>\n",
       "      <th>HASPRONOUNS</th>\n",
       "      <th>ISHARASSMENT</th>\n",
       "      <th>AUTO_ISHARASSMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1371969703027953666</td>\n",
       "      <td>1227977888860798982</td>\n",
       "      <td>This man Will Barton is 6'5 wearing super skinnie jeans with his knee out. Idc about this fags ego the Nuggets need to start MPJ police loving ass</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1371970229010534401</td>\n",
       "      <td>1111839485874995200</td>\n",
       "      <td>@horansarizona stfu dyke</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1372542942087364609</td>\n",
       "      <td>1050750048475209730</td>\n",
       "      <td>i remember I was dating this dyke who constantly tweeted about how much she liked big booty girls with tiny waists but could not begin to understand why I felt so offended by it. this is the reason right here, because I’m clearly not your type https://t.co/KP8LqVIgOM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1371242299519303681</td>\n",
       "      <td>1342695061151166472</td>\n",
       "      <td>Gibbs said \"I'll never let this industry demasculinize me\" with all this batty boy shit going on in the industry he never had a chance...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1371955536619433985</td>\n",
       "      <td>1237100903347269639</td>\n",
       "      <td>@MrsLadyValkyrie @glowingcanary @CompelLearning @hondo64ou1 @back2monke @LindseyBoylan I probably know more than you pansy ass ever will.  I am very knowledgeable  that's why I can take the stance I do. From knowledge and experience. And I know bull shit when I see it.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1371949548021690377</td>\n",
       "      <td>1358657061467222018</td>\n",
       "      <td>TG: shut up karkat\\nTG: you fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1365280595081797633</td>\n",
       "      <td>1195598451729321984</td>\n",
       "      <td>@schizoidfemdog That faggot is so annoying and hot God</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TWEETID               USERID  \\\n",
       "466  1371969703027953666  1227977888860798982   \n",
       "464  1371970229010534401  1111839485874995200   \n",
       "198  1372542942087364609  1050750048475209730   \n",
       "353  1371242299519303681  1342695061151166472   \n",
       "484  1371955536619433985  1237100903347269639   \n",
       "499  1371949548021690377  1358657061467222018   \n",
       "149  1365280595081797633  1195598451729321984   \n",
       "\n",
       "                                                                                                                                                                                                                                                                             TWEET  \\\n",
       "466  This man Will Barton is 6'5 wearing super skinnie jeans with his knee out. Idc about this fags ego the Nuggets need to start MPJ police loving ass                                                                                                                              \n",
       "464  @horansarizona stfu dyke                                                                                                                                                                                                                                                        \n",
       "198  i remember I was dating this dyke who constantly tweeted about how much she liked big booty girls with tiny waists but could not begin to understand why I felt so offended by it. this is the reason right here, because I’m clearly not your type https://t.co/KP8LqVIgOM     \n",
       "353  Gibbs said \"I'll never let this industry demasculinize me\" with all this batty boy shit going on in the industry he never had a chance...                                                                                                                                       \n",
       "484  @MrsLadyValkyrie @glowingcanary @CompelLearning @hondo64ou1 @back2monke @LindseyBoylan I probably know more than you pansy ass ever will.  I am very knowledgeable  that's why I can take the stance I do. From knowledge and experience. And I know bull shit when I see it.   \n",
       "499  TG: shut up karkat\\nTG: you fag                                                                                                                                                                                                                                                 \n",
       "149  @schizoidfemdog That faggot is so annoying and hot God                                                                                                                                                                                                                          \n",
       "\n",
       "     ISTYPEHOMOSEXUAL  ISTYPETRANSGENDER  ISTYPEBISEXUAL  HASPRONOUNS  \\\n",
       "466  1                 0                  0               0.0           \n",
       "464  1                 0                  0               1.0           \n",
       "198  1                 0                  0               0.0           \n",
       "353  0                 0                  0               0.0           \n",
       "484  1                 0                  0               0.0           \n",
       "499  1                 0                  0               0.0           \n",
       "149  1                 0                  0               0.0           \n",
       "\n",
       "     ISHARASSMENT AUTO_ISHARASSMENT  \n",
       "466  1             None              \n",
       "464  1             None              \n",
       "198  1             None              \n",
       "353  1             None              \n",
       "484  1             None              \n",
       "499  1             None              \n",
       "149  1             None              "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 2])\n",
    "df_train.iloc[buckets[(ABSTAIN, POSITIVE)]].sample(7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:00<00:00, 5845.45it/s]\n"
     ]
    }
   ],
   "source": [
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>names_or_places</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_insults</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_to_person</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descriptive_bad</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>against_nature</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigger_warning</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bender_as_drunk</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bender_pop_culture</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_using_cigarettes</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slur_in_handles</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.169591</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_pronouns</th>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j Polarity  Coverage  Overlaps  Conflicts\n",
       "names_or_places         0   [0]      0.061404  0.002924  0.000000 \n",
       "simple_insults          1   [1]      0.011696  0.000000  0.000000 \n",
       "term_to_person          2   [1]      0.020468  0.002924  0.002924 \n",
       "descriptive_bad         3   [1]      0.014620  0.000000  0.000000 \n",
       "against_nature          4   [1]      0.002924  0.000000  0.000000 \n",
       "trigger_warning         5   [0]      0.005848  0.000000  0.000000 \n",
       "bender_as_drunk         6   [0]      0.005848  0.000000  0.000000 \n",
       "bender_pop_culture      7   [0]      0.017544  0.002924  0.000000 \n",
       "slang_using_cigarettes  8   [0]      0.011696  0.002924  0.000000 \n",
       "slur_in_handles         9   [0]      0.169591  0.029240  0.000000 \n",
       "has_pronouns            10  [0]      0.102339  0.040936  0.002924 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1, -1,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1,  0, -1,  0,\n",
       "        0, -1, -1,  0, -1, -1,  0, -1, -1, -1, -1,  0,  0, -1, -1, -1, -1,\n",
       "       -1,  0, -1, -1, -1,  1,  0, -1,  0,  0, -1, -1, -1, -1, -1,  0, -1,\n",
       "        0,  1,  0, -1, -1,  0, -1, -1, -1,  0, -1, -1,  0, -1,  0, -1,  0,\n",
       "        0,  0, -1,  0, -1, -1,  0,  0, -1,  0, -1,  1, -1, -1, -1, -1, -1,\n",
       "        0, -1,  0, -1,  0,  1, -1,  0, -1,  0, -1, -1, -1, -1, -1, -1,  0,\n",
       "        0, -1,  0,  0,  0,  0,  0, -1, -1,  0,  0, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  0, -1, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0,  0, -1, -1,\n",
       "        0, -1, -1, -1, -1,  0,  0,  1,  0, -1,  0, -1, -1, -1, -1,  0, -1,\n",
       "       -1, -1,  0, -1, -1, -1,  0, -1,  0, -1, -1,  0, -1, -1, -1,  0, -1,\n",
       "       -1,  0,  0, -1, -1,  0,  0,  1,  0, -1, -1,  0,  0,  0, -1,  0, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1,  1, -1,  0,  0, -1, -1, -1,  0,  0, -1,\n",
       "        0, -1,  1, -1, -1, -1,  0, -1, -1,  0, -1, -1,  0, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0, -1,  0,\n",
       "       -1, -1, -1, -1,  0, -1,  1, -1, -1,  0, -1,  0, -1,  0, -1, -1,  0,\n",
       "        0, -1,  0,  0, -1, -1, -1,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1,  0, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1,  1,  0, -1,\n",
       "        0, -1, -1, -1,  0,  0, -1, -1, -1,  1, -1, -1, -1, -1,  0, -1, -1,\n",
       "       -1,  0,  1,  0,  0,  0,  0,  0, -1, -1, -1,  0, -1,  0, -1,  1, -1,\n",
       "       -1, -1,  0,  0,  0, -1,  0,  0,  1, -1, -1, -1, -1,  0, -1, -1, -1,\n",
       "       -1, -1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   59.8%\n",
      "Label Model Accuracy:     44.970414%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.TWEET.tolist())\n",
    "X_test = vectorizer.transform(df_test.TWEET.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
