{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import sqlite3\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Connect to DB\n",
    "conn = sqlite3.connect(\"../../etc/database_store/auto_tweets_2.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets in DB:  120798\n",
      "Total Manual Labelled tweets in DB:  1536\n",
      "Total Manual Labelled tweets in DB:  66321\n"
     ]
    }
   ],
   "source": [
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "    #Construct SQL Queries\n",
    "    #Count Total amount of Tweets in Database\n",
    "    cur.execute(\"SELECT COUNT(USERID) FROM TWEETS\")\n",
    "    print(\"Total Tweets in DB: \", cur.fetchall()[0][0])\n",
    "    #Count amount of manually labelled tweets currently in Database\n",
    "    cur.execute(\"SELECT COUNT(USERID) FROM TWEETS WHERE ISHARASSMENT IS NOT NULL\")\n",
    "    print(\"Total Manual Labelled tweets in DB: \", cur.fetchall()[0][0])\n",
    "    #Count amount of automatically labelled tweets currently in Database\n",
    "    cur.execute(\"SELECT COUNT(USERID) FROM TWEETS WHERE AUTO_ISHARASSMENT IS NOT NULL\")\n",
    "    print(\"Total Manual Labelled tweets in DB: \", cur.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain all labelled tweets from DB\n",
    "pd_data = pd.read_sql(con=conn,sql=\"SELECT * FROM TWEETS WHERE AUTO_ISHARASSMENT IS NOT NULL OR ISHARASSMENT IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22261"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sample of data to save memory. Using full dataset causes Kernel to crash from memory overflow on 16GB system\n",
    "pd_data = pd_data.sample(n=22000, random_state=70824426)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "    \n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataframe:  12.2 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"size of dataframe: \", convert_size(sys.getsizeof(pd_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>ISTYPEHOMOSEXUAL</th>\n",
       "      <th>ISTYPETRANSGENDER</th>\n",
       "      <th>ISTYPEBISEXUAL</th>\n",
       "      <th>HASPRONOUNS</th>\n",
       "      <th>ISHARASSMENT</th>\n",
       "      <th>AUTO_ISHARASSMENT</th>\n",
       "      <th>PASTEXPERIENCE</th>\n",
       "      <th>AUTO_PASTEXPERIENCE</th>\n",
       "      <th>CLEAN_TWEET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13935</th>\n",
       "      <td>1376217439940251651</td>\n",
       "      <td>1221213601559666688</td>\n",
       "      <td>@ilovebram2 nah kataraâ€™s the best bender i sai...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ilovebram nah katara the best bender i said wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>1374509846347718658</td>\n",
       "      <td>242759164</td>\n",
       "      <td>@BorisJohnson Hey Doris which you want Restaur...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>borisjohnson hey doris which you want restaura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11459</th>\n",
       "      <td>1375428519346380805</td>\n",
       "      <td>1315261675944124416</td>\n",
       "      <td>@Fag_Prince Good morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>fagprince good morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18387</th>\n",
       "      <td>1377751657459589120</td>\n",
       "      <td>1145706546309083136</td>\n",
       "      <td>@fIwrchuu slur // \\n\\nyou called me a fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>fiwrchuu slur you called me a fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>1382479737864396803</td>\n",
       "      <td>773560017945554945</td>\n",
       "      <td>i knew dominic fike was rlly dominic fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>i knew dominic like was rlly dominic fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17277</th>\n",
       "      <td>1377372355886870533</td>\n",
       "      <td>2564305129</td>\n",
       "      <td>@5MIl3MUSIC Meet me in the pit you pansy https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>milmusic meet me in the pit you pansy httpstco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13914</th>\n",
       "      <td>1376219361808166912</td>\n",
       "      <td>1171577501946142735</td>\n",
       "      <td>@tjamesgaralt I'll do it again faggot https://...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>tjamesgaralt ill do it again faggot httpstcogp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13088</th>\n",
       "      <td>1376287255212347398</td>\n",
       "      <td>2419976203</td>\n",
       "      <td>@shadowsoobin did u just call me an ugly dyke?...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>shadowsoobin did u just call me an ugly dyke d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>1376304929250418689</td>\n",
       "      <td>1367989557879275520</td>\n",
       "      <td>Got my hair tied back like van dyke rn https:/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>got my hair tied back like van dyke in httpstc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16924</th>\n",
       "      <td>1377400095801364486</td>\n",
       "      <td>1108388153000288258</td>\n",
       "      <td>Good morning \\nMisty morning..... \\nðŸ“· Micah A....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>good morning misty morning micah a ponce https...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TWEETID               USERID  \\\n",
       "13935  1376217439940251651  1221213601559666688   \n",
       "7184   1374509846347718658            242759164   \n",
       "11459  1375428519346380805  1315261675944124416   \n",
       "18387  1377751657459589120  1145706546309083136   \n",
       "19575  1382479737864396803   773560017945554945   \n",
       "...                    ...                  ...   \n",
       "17277  1377372355886870533           2564305129   \n",
       "13914  1376219361808166912  1171577501946142735   \n",
       "13088  1376287255212347398           2419976203   \n",
       "12842  1376304929250418689  1367989557879275520   \n",
       "16924  1377400095801364486  1108388153000288258   \n",
       "\n",
       "                                                   TWEET  ISTYPEHOMOSEXUAL  \\\n",
       "13935  @ilovebram2 nah kataraâ€™s the best bender i sai...                 1   \n",
       "7184   @BorisJohnson Hey Doris which you want Restaur...                 1   \n",
       "11459                           @Fag_Prince Good morning                 0   \n",
       "18387          @fIwrchuu slur // \\n\\nyou called me a fag                 1   \n",
       "19575           i knew dominic fike was rlly dominic fag                 1   \n",
       "...                                                  ...               ...   \n",
       "17277  @5MIl3MUSIC Meet me in the pit you pansy https...                 1   \n",
       "13914  @tjamesgaralt I'll do it again faggot https://...                 1   \n",
       "13088  @shadowsoobin did u just call me an ugly dyke?...                 1   \n",
       "12842  Got my hair tied back like van dyke rn https:/...                 1   \n",
       "16924  Good morning \\nMisty morning..... \\nðŸ“· Micah A....                 0   \n",
       "\n",
       "       ISTYPETRANSGENDER  ISTYPEBISEXUAL  HASPRONOUNS  ISHARASSMENT  \\\n",
       "13935                  0               0          0.0           NaN   \n",
       "7184                   0               0          0.0           NaN   \n",
       "11459                  0               0          0.0           NaN   \n",
       "18387                  0               0          0.0           NaN   \n",
       "19575                  0               0          1.0           NaN   \n",
       "...                  ...             ...          ...           ...   \n",
       "17277                  0               0          0.0           NaN   \n",
       "13914                  0               0          1.0           NaN   \n",
       "13088                  0               0          1.0           NaN   \n",
       "12842                  0               0          0.0           NaN   \n",
       "16924                  0               0          0.0           NaN   \n",
       "\n",
       "       AUTO_ISHARASSMENT  PASTEXPERIENCE AUTO_PASTEXPERIENCE  \\\n",
       "13935                0.0             NaN                None   \n",
       "7184                 0.0             NaN                None   \n",
       "11459                0.0             NaN                None   \n",
       "18387                0.0             NaN                None   \n",
       "19575                0.0             NaN                None   \n",
       "...                  ...             ...                 ...   \n",
       "17277                1.0             NaN                None   \n",
       "13914                0.0             NaN                None   \n",
       "13088                0.0             NaN                None   \n",
       "12842                0.0             NaN                None   \n",
       "16924                0.0             NaN                None   \n",
       "\n",
       "                                             CLEAN_TWEET  \n",
       "13935  ilovebram nah katara the best bender i said wh...  \n",
       "7184   borisjohnson hey doris which you want restaura...  \n",
       "11459                             fagprince good morning  \n",
       "18387                  fiwrchuu slur you called me a fag  \n",
       "19575           i knew dominic like was rlly dominic fag  \n",
       "...                                                  ...  \n",
       "17277  milmusic meet me in the pit you pansy httpstco...  \n",
       "13914  tjamesgaralt ill do it again faggot httpstcogp...  \n",
       "13088  shadowsoobin did u just call me an ugly dyke d...  \n",
       "12842  got my hair tied back like van dyke in httpstc...  \n",
       "16924  good morning misty morning micah a ponce https...  \n",
       "\n",
       "[22000 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 ISHARASSMENT is 0\n",
      "35 ISHARASSMENT is 1\n",
      "36 ISHARASSMENT is 0\n",
      "97 ISHARASSMENT is 0\n",
      "144 ISHARASSMENT is 0\n",
      "193 ISHARASSMENT is 0\n",
      "222 ISHARASSMENT is 1\n",
      "240 ISHARASSMENT is 0\n",
      "299 ISHARASSMENT is 0\n",
      "316 ISHARASSMENT is 0\n",
      "375 ISHARASSMENT is 0\n",
      "399 ISHARASSMENT is 0\n",
      "436 ISHARASSMENT is 0\n",
      "477 ISHARASSMENT is 0\n",
      "584 ISHARASSMENT is 1\n",
      "638 ISHARASSMENT is 0\n",
      "685 ISHARASSMENT is 0\n",
      "746 ISHARASSMENT is 1\n",
      "756 ISHARASSMENT is 0\n",
      "777 ISHARASSMENT is 1\n",
      "815 ISHARASSMENT is 0\n",
      "855 ISHARASSMENT is 0\n",
      "872 ISHARASSMENT is 1\n",
      "908 ISHARASSMENT is 0\n",
      "925 ISHARASSMENT is 0\n",
      "927 ISHARASSMENT is 0\n",
      "955 ISHARASSMENT is 0\n",
      "1116 ISHARASSMENT is 0\n",
      "1130 ISHARASSMENT is 1\n",
      "1135 ISHARASSMENT is 0\n",
      "1184 ISHARASSMENT is 0\n",
      "1212 ISHARASSMENT is 0\n",
      "1219 ISHARASSMENT is 0\n",
      "1221 ISHARASSMENT is 1\n",
      "1252 ISHARASSMENT is 1\n",
      "1338 ISHARASSMENT is 0\n",
      "1352 ISHARASSMENT is 0\n",
      "1424 ISHARASSMENT is 1\n",
      "1531 ISHARASSMENT is 0\n",
      "1582 ISHARASSMENT is 1\n",
      "1613 ISHARASSMENT is 0\n",
      "1750 ISHARASSMENT is 0\n",
      "1761 ISHARASSMENT is 0\n",
      "1825 ISHARASSMENT is 0\n",
      "1837 ISHARASSMENT is 0\n",
      "2023 ISHARASSMENT is 0\n",
      "2059 ISHARASSMENT is 0\n",
      "2114 ISHARASSMENT is 0\n",
      "2180 ISHARASSMENT is 0\n",
      "2193 ISHARASSMENT is 0\n",
      "2249 ISHARASSMENT is 0\n",
      "2403 ISHARASSMENT is 1\n",
      "2417 ISHARASSMENT is 0\n",
      "2431 ISHARASSMENT is 1\n",
      "2485 ISHARASSMENT is 0\n",
      "2559 ISHARASSMENT is 0\n",
      "2570 ISHARASSMENT is 0\n",
      "2592 ISHARASSMENT is 1\n",
      "2704 ISHARASSMENT is 1\n",
      "2750 ISHARASSMENT is 0\n",
      "2806 ISHARASSMENT is 0\n",
      "2826 ISHARASSMENT is 0\n",
      "2866 ISHARASSMENT is 0\n",
      "2874 ISHARASSMENT is 0\n",
      "2918 ISHARASSMENT is 0\n",
      "2940 ISHARASSMENT is 1\n",
      "2945 ISHARASSMENT is 0\n",
      "3053 ISHARASSMENT is 0\n",
      "3116 ISHARASSMENT is 0\n",
      "3126 ISHARASSMENT is 0\n",
      "3142 ISHARASSMENT is 0\n",
      "3157 ISHARASSMENT is 1\n",
      "3159 ISHARASSMENT is 0\n",
      "3206 ISHARASSMENT is 1\n",
      "3225 ISHARASSMENT is 1\n",
      "3247 ISHARASSMENT is 0\n",
      "3264 ISHARASSMENT is 0\n",
      "3282 ISHARASSMENT is 0\n",
      "3285 ISHARASSMENT is 0\n",
      "3347 ISHARASSMENT is 0\n",
      "3361 ISHARASSMENT is 1\n",
      "3383 ISHARASSMENT is 0\n",
      "3458 ISHARASSMENT is 0\n",
      "3524 ISHARASSMENT is 0\n",
      "3562 ISHARASSMENT is 1\n",
      "3609 ISHARASSMENT is 0\n",
      "3619 ISHARASSMENT is 0\n",
      "3647 ISHARASSMENT is 1\n",
      "3668 ISHARASSMENT is 0\n",
      "3796 ISHARASSMENT is 0\n",
      "3824 ISHARASSMENT is 0\n",
      "3873 ISHARASSMENT is 0\n",
      "3886 ISHARASSMENT is 0\n",
      "3902 ISHARASSMENT is 0\n",
      "3912 ISHARASSMENT is 0\n",
      "3937 ISHARASSMENT is 0\n",
      "3989 ISHARASSMENT is 0\n",
      "3990 ISHARASSMENT is 0\n",
      "4050 ISHARASSMENT is 0\n",
      "4136 ISHARASSMENT is 0\n",
      "4157 ISHARASSMENT is 0\n",
      "4168 ISHARASSMENT is 0\n",
      "4286 ISHARASSMENT is 1\n",
      "4376 ISHARASSMENT is 0\n",
      "4441 ISHARASSMENT is 0\n",
      "4475 ISHARASSMENT is 0\n",
      "4525 ISHARASSMENT is 0\n",
      "4539 ISHARASSMENT is 1\n",
      "4547 ISHARASSMENT is 0\n",
      "4602 ISHARASSMENT is 0\n",
      "4628 ISHARASSMENT is 0\n",
      "4652 ISHARASSMENT is 0\n",
      "4659 ISHARASSMENT is 0\n",
      "4732 ISHARASSMENT is 0\n",
      "4758 ISHARASSMENT is 0\n",
      "4792 ISHARASSMENT is 0\n",
      "4803 ISHARASSMENT is 1\n",
      "4848 ISHARASSMENT is 0\n",
      "4936 ISHARASSMENT is 1\n",
      "4939 ISHARASSMENT is 0\n",
      "4993 ISHARASSMENT is 0\n",
      "4999 ISHARASSMENT is 0\n",
      "5079 ISHARASSMENT is 0\n",
      "5229 ISHARASSMENT is 0\n",
      "5251 ISHARASSMENT is 1\n",
      "5253 ISHARASSMENT is 0\n",
      "5348 ISHARASSMENT is 1\n",
      "5379 ISHARASSMENT is 0\n",
      "5431 ISHARASSMENT is 1\n",
      "5765 ISHARASSMENT is 0\n",
      "5807 ISHARASSMENT is 1\n",
      "5852 ISHARASSMENT is 0\n",
      "5887 ISHARASSMENT is 0\n",
      "5890 ISHARASSMENT is 0\n",
      "5950 ISHARASSMENT is 0\n",
      "5983 ISHARASSMENT is 0\n",
      "6102 ISHARASSMENT is 1\n",
      "6173 ISHARASSMENT is 0\n",
      "6194 ISHARASSMENT is 1\n",
      "6406 ISHARASSMENT is 0\n",
      "6512 ISHARASSMENT is 0\n",
      "6602 ISHARASSMENT is 0\n",
      "6628 ISHARASSMENT is 1\n",
      "6681 ISHARASSMENT is 0\n",
      "6717 ISHARASSMENT is 0\n",
      "6739 ISHARASSMENT is 0\n",
      "6740 ISHARASSMENT is 0\n",
      "6848 ISHARASSMENT is 0\n",
      "6921 ISHARASSMENT is 0\n",
      "6927 ISHARASSMENT is 0\n",
      "6935 ISHARASSMENT is 0\n",
      "6997 ISHARASSMENT is 0\n",
      "7052 ISHARASSMENT is 0\n",
      "7139 ISHARASSMENT is 0\n",
      "7185 ISHARASSMENT is 0\n",
      "7209 ISHARASSMENT is 1\n",
      "7265 ISHARASSMENT is 0\n",
      "7339 ISHARASSMENT is 1\n",
      "7354 ISHARASSMENT is 0\n",
      "7363 ISHARASSMENT is 0\n",
      "7383 ISHARASSMENT is 0\n",
      "7500 ISHARASSMENT is 0\n",
      "7554 ISHARASSMENT is 0\n",
      "7566 ISHARASSMENT is 0\n",
      "7570 ISHARASSMENT is 0\n",
      "7642 ISHARASSMENT is 0\n",
      "7662 ISHARASSMENT is 0\n",
      "7679 ISHARASSMENT is 0\n",
      "7713 ISHARASSMENT is 0\n",
      "7720 ISHARASSMENT is 0\n",
      "7751 ISHARASSMENT is 0\n",
      "7756 ISHARASSMENT is 0\n",
      "7773 ISHARASSMENT is 0\n",
      "7817 ISHARASSMENT is 0\n",
      "7902 ISHARASSMENT is 0\n",
      "7926 ISHARASSMENT is 0\n",
      "8039 ISHARASSMENT is 0\n",
      "8075 ISHARASSMENT is 1\n",
      "8078 ISHARASSMENT is 0\n",
      "8087 ISHARASSMENT is 0\n",
      "8137 ISHARASSMENT is 0\n",
      "8147 ISHARASSMENT is 0\n",
      "8170 ISHARASSMENT is 1\n",
      "8221 ISHARASSMENT is 0\n",
      "8237 ISHARASSMENT is 0\n",
      "8262 ISHARASSMENT is 0\n",
      "8269 ISHARASSMENT is 0\n",
      "8340 ISHARASSMENT is 0\n",
      "8464 ISHARASSMENT is 0\n",
      "8563 ISHARASSMENT is 0\n",
      "8611 ISHARASSMENT is 0\n",
      "8724 ISHARASSMENT is 0\n",
      "8732 ISHARASSMENT is 0\n",
      "8739 ISHARASSMENT is 0\n",
      "8748 ISHARASSMENT is 0\n",
      "8764 ISHARASSMENT is 0\n",
      "8785 ISHARASSMENT is 0\n",
      "8799 ISHARASSMENT is 0\n",
      "8864 ISHARASSMENT is 0\n",
      "8919 ISHARASSMENT is 1\n",
      "8954 ISHARASSMENT is 0\n",
      "8957 ISHARASSMENT is 0\n",
      "9055 ISHARASSMENT is 0\n",
      "9101 ISHARASSMENT is 0\n",
      "9148 ISHARASSMENT is 0\n",
      "9219 ISHARASSMENT is 0\n",
      "9233 ISHARASSMENT is 0\n",
      "9291 ISHARASSMENT is 1\n",
      "9470 ISHARASSMENT is 0\n",
      "9518 ISHARASSMENT is 0\n",
      "9528 ISHARASSMENT is 0\n",
      "9581 ISHARASSMENT is 1\n",
      "9591 ISHARASSMENT is 1\n",
      "9608 ISHARASSMENT is 0\n",
      "9616 ISHARASSMENT is 0\n",
      "9677 ISHARASSMENT is 1\n",
      "9762 ISHARASSMENT is 1\n",
      "9874 ISHARASSMENT is 1\n",
      "9914 ISHARASSMENT is 1\n",
      "9927 ISHARASSMENT is 0\n",
      "10099 ISHARASSMENT is 0\n",
      "10105 ISHARASSMENT is 0\n",
      "10139 ISHARASSMENT is 0\n",
      "10255 ISHARASSMENT is 0\n",
      "10284 ISHARASSMENT is 0\n",
      "10340 ISHARASSMENT is 1\n",
      "10342 ISHARASSMENT is 1\n",
      "10417 ISHARASSMENT is 1\n",
      "10421 ISHARASSMENT is 0\n",
      "10492 ISHARASSMENT is 0\n",
      "10513 ISHARASSMENT is 0\n",
      "10616 ISHARASSMENT is 0\n",
      "10639 ISHARASSMENT is 0\n",
      "10679 ISHARASSMENT is 0\n",
      "10842 ISHARASSMENT is 0\n",
      "10863 ISHARASSMENT is 0\n",
      "10866 ISHARASSMENT is 0\n",
      "10876 ISHARASSMENT is 0\n",
      "10967 ISHARASSMENT is 0\n",
      "10974 ISHARASSMENT is 1\n",
      "10991 ISHARASSMENT is 0\n",
      "11014 ISHARASSMENT is 0\n",
      "11091 ISHARASSMENT is 0\n",
      "11175 ISHARASSMENT is 0\n",
      "11230 ISHARASSMENT is 0\n",
      "11280 ISHARASSMENT is 0\n",
      "11289 ISHARASSMENT is 0\n",
      "11337 ISHARASSMENT is 0\n",
      "11350 ISHARASSMENT is 0\n",
      "11479 ISHARASSMENT is 0\n",
      "11500 ISHARASSMENT is 1\n",
      "11649 ISHARASSMENT is 0\n",
      "11652 ISHARASSMENT is 1\n",
      "11670 ISHARASSMENT is 1\n",
      "11693 ISHARASSMENT is 0\n",
      "11710 ISHARASSMENT is 0\n",
      "11711 ISHARASSMENT is 0\n",
      "11714 ISHARASSMENT is 0\n",
      "11782 ISHARASSMENT is 1\n",
      "11801 ISHARASSMENT is 0\n",
      "11824 ISHARASSMENT is 0\n",
      "11830 ISHARASSMENT is 1\n",
      "11901 ISHARASSMENT is 0\n",
      "11914 ISHARASSMENT is 0\n",
      "11945 ISHARASSMENT is 0\n",
      "11954 ISHARASSMENT is 0\n",
      "11958 ISHARASSMENT is 0\n",
      "11960 ISHARASSMENT is 0\n",
      "11961 ISHARASSMENT is 1\n",
      "11962 ISHARASSMENT is 0\n",
      "12016 ISHARASSMENT is 0\n",
      "12055 ISHARASSMENT is 1\n",
      "12076 ISHARASSMENT is 1\n",
      "12161 ISHARASSMENT is 1\n",
      "12166 ISHARASSMENT is 0\n",
      "12190 ISHARASSMENT is 0\n",
      "12201 ISHARASSMENT is 0\n",
      "12214 ISHARASSMENT is 0\n",
      "12316 ISHARASSMENT is 0\n",
      "12321 ISHARASSMENT is 0\n",
      "12328 ISHARASSMENT is 0\n",
      "12401 ISHARASSMENT is 1\n",
      "12408 ISHARASSMENT is 0\n",
      "12471 ISHARASSMENT is 0\n",
      "12517 ISHARASSMENT is 0\n",
      "12546 ISHARASSMENT is 1\n",
      "12548 ISHARASSMENT is 0\n",
      "12632 ISHARASSMENT is 0\n",
      "12660 ISHARASSMENT is 0\n",
      "12674 ISHARASSMENT is 1\n",
      "12680 ISHARASSMENT is 0\n",
      "12746 ISHARASSMENT is 1\n",
      "12781 ISHARASSMENT is 0\n",
      "12850 ISHARASSMENT is 0\n",
      "12894 ISHARASSMENT is 1\n",
      "12921 ISHARASSMENT is 0\n",
      "12990 ISHARASSMENT is 0\n",
      "13134 ISHARASSMENT is 1\n",
      "13137 ISHARASSMENT is 1\n",
      "13157 ISHARASSMENT is 0\n",
      "13266 ISHARASSMENT is 1\n",
      "13290 ISHARASSMENT is 0\n",
      "13377 ISHARASSMENT is 0\n",
      "13385 ISHARASSMENT is 0\n",
      "13397 ISHARASSMENT is 1\n",
      "13402 ISHARASSMENT is 0\n",
      "13449 ISHARASSMENT is 1\n",
      "13463 ISHARASSMENT is 0\n",
      "13466 ISHARASSMENT is 0\n",
      "13491 ISHARASSMENT is 1\n",
      "13522 ISHARASSMENT is 0\n",
      "13587 ISHARASSMENT is 0\n",
      "13657 ISHARASSMENT is 0\n",
      "13665 ISHARASSMENT is 1\n",
      "13713 ISHARASSMENT is 0\n",
      "13777 ISHARASSMENT is 0\n",
      "13830 ISHARASSMENT is 0\n",
      "13846 ISHARASSMENT is 0\n",
      "13868 ISHARASSMENT is 0\n",
      "13877 ISHARASSMENT is 1\n",
      "13907 ISHARASSMENT is 0\n",
      "13916 ISHARASSMENT is 1\n",
      "13951 ISHARASSMENT is 0\n",
      "14002 ISHARASSMENT is 1\n",
      "14054 ISHARASSMENT is 0\n",
      "14171 ISHARASSMENT is 0\n",
      "14181 ISHARASSMENT is 0\n",
      "14215 ISHARASSMENT is 0\n",
      "14252 ISHARASSMENT is 0\n",
      "14282 ISHARASSMENT is 0\n",
      "14337 ISHARASSMENT is 0\n",
      "14361 ISHARASSMENT is 0\n",
      "14446 ISHARASSMENT is 0\n",
      "14659 ISHARASSMENT is 0\n",
      "14661 ISHARASSMENT is 0\n",
      "14686 ISHARASSMENT is 1\n",
      "14716 ISHARASSMENT is 1\n",
      "14778 ISHARASSMENT is 1\n",
      "14836 ISHARASSMENT is 0\n",
      "14861 ISHARASSMENT is 1\n",
      "14871 ISHARASSMENT is 1\n",
      "14877 ISHARASSMENT is 0\n",
      "14933 ISHARASSMENT is 0\n",
      "14936 ISHARASSMENT is 0\n",
      "15061 ISHARASSMENT is 0\n",
      "15153 ISHARASSMENT is 0\n",
      "15224 ISHARASSMENT is 1\n",
      "15229 ISHARASSMENT is 0\n",
      "15300 ISHARASSMENT is 0\n",
      "15304 ISHARASSMENT is 0\n",
      "15317 ISHARASSMENT is 0\n",
      "15323 ISHARASSMENT is 0\n",
      "15335 ISHARASSMENT is 1\n",
      "15345 ISHARASSMENT is 0\n",
      "15516 ISHARASSMENT is 0\n",
      "15672 ISHARASSMENT is 0\n",
      "15683 ISHARASSMENT is 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15790 ISHARASSMENT is 1\n",
      "15875 ISHARASSMENT is 1\n",
      "15886 ISHARASSMENT is 0\n",
      "15980 ISHARASSMENT is 0\n",
      "15982 ISHARASSMENT is 1\n",
      "16042 ISHARASSMENT is 0\n",
      "16154 ISHARASSMENT is 0\n",
      "16170 ISHARASSMENT is 1\n",
      "16179 ISHARASSMENT is 1\n",
      "16283 ISHARASSMENT is 0\n",
      "16296 ISHARASSMENT is 0\n",
      "16399 ISHARASSMENT is 0\n",
      "16418 ISHARASSMENT is 0\n",
      "16437 ISHARASSMENT is 1\n",
      "16460 ISHARASSMENT is 0\n",
      "16490 ISHARASSMENT is 0\n",
      "16502 ISHARASSMENT is 0\n",
      "16527 ISHARASSMENT is 0\n",
      "16532 ISHARASSMENT is 0\n",
      "16576 ISHARASSMENT is 0\n",
      "16604 ISHARASSMENT is 0\n",
      "16642 ISHARASSMENT is 0\n",
      "16673 ISHARASSMENT is 0\n",
      "16686 ISHARASSMENT is 1\n",
      "16716 ISHARASSMENT is 0\n",
      "16735 ISHARASSMENT is 1\n",
      "16802 ISHARASSMENT is 0\n",
      "16835 ISHARASSMENT is 0\n",
      "16844 ISHARASSMENT is 0\n",
      "16877 ISHARASSMENT is 0\n",
      "16891 ISHARASSMENT is 0\n",
      "16959 ISHARASSMENT is 0\n",
      "16974 ISHARASSMENT is 0\n",
      "17021 ISHARASSMENT is 1\n",
      "17047 ISHARASSMENT is 1\n",
      "17051 ISHARASSMENT is 0\n",
      "17125 ISHARASSMENT is 0\n",
      "17139 ISHARASSMENT is 0\n",
      "17175 ISHARASSMENT is 0\n",
      "17233 ISHARASSMENT is 0\n",
      "17283 ISHARASSMENT is 0\n",
      "17288 ISHARASSMENT is 1\n",
      "17301 ISHARASSMENT is 0\n",
      "17302 ISHARASSMENT is 0\n",
      "17371 ISHARASSMENT is 0\n",
      "17474 ISHARASSMENT is 0\n",
      "17609 ISHARASSMENT is 0\n",
      "17701 ISHARASSMENT is 0\n",
      "17708 ISHARASSMENT is 0\n",
      "17762 ISHARASSMENT is 0\n",
      "17822 ISHARASSMENT is 1\n",
      "17842 ISHARASSMENT is 1\n",
      "17861 ISHARASSMENT is 0\n",
      "17886 ISHARASSMENT is 0\n",
      "17906 ISHARASSMENT is 1\n",
      "17961 ISHARASSMENT is 0\n",
      "17973 ISHARASSMENT is 0\n",
      "17980 ISHARASSMENT is 0\n",
      "18006 ISHARASSMENT is 0\n",
      "18065 ISHARASSMENT is 1\n",
      "18137 ISHARASSMENT is 0\n",
      "18198 ISHARASSMENT is 1\n",
      "18220 ISHARASSMENT is 0\n",
      "18289 ISHARASSMENT is 0\n",
      "18356 ISHARASSMENT is 0\n",
      "18398 ISHARASSMENT is 0\n",
      "18407 ISHARASSMENT is 0\n",
      "18427 ISHARASSMENT is 0\n",
      "18428 ISHARASSMENT is 0\n",
      "18445 ISHARASSMENT is 0\n",
      "18461 ISHARASSMENT is 1\n",
      "18504 ISHARASSMENT is 0\n",
      "18508 ISHARASSMENT is 0\n",
      "18573 ISHARASSMENT is 0\n",
      "18631 ISHARASSMENT is 0\n",
      "18747 ISHARASSMENT is 1\n",
      "18776 ISHARASSMENT is 0\n",
      "18807 ISHARASSMENT is 0\n",
      "18836 ISHARASSMENT is 0\n",
      "18884 ISHARASSMENT is 0\n",
      "18906 ISHARASSMENT is 0\n",
      "18947 ISHARASSMENT is 0\n",
      "19078 ISHARASSMENT is 0\n",
      "19103 ISHARASSMENT is 1\n",
      "19186 ISHARASSMENT is 1\n",
      "19241 ISHARASSMENT is 1\n",
      "19311 ISHARASSMENT is 0\n",
      "19342 ISHARASSMENT is 0\n",
      "19435 ISHARASSMENT is 0\n",
      "19463 ISHARASSMENT is 0\n",
      "19470 ISHARASSMENT is 0\n",
      "19602 ISHARASSMENT is 0\n",
      "19605 ISHARASSMENT is 0\n",
      "19607 ISHARASSMENT is 1\n",
      "19616 ISHARASSMENT is 0\n",
      "19619 ISHARASSMENT is 0\n",
      "19669 ISHARASSMENT is 1\n",
      "19703 ISHARASSMENT is 0\n",
      "19743 ISHARASSMENT is 1\n",
      "19746 ISHARASSMENT is 0\n",
      "19762 ISHARASSMENT is 1\n",
      "19901 ISHARASSMENT is 0\n",
      "19922 ISHARASSMENT is 0\n",
      "19947 ISHARASSMENT is 0\n",
      "19954 ISHARASSMENT is 0\n",
      "19993 ISHARASSMENT is 0\n",
      "20045 ISHARASSMENT is 1\n",
      "20050 ISHARASSMENT is 0\n",
      "20089 ISHARASSMENT is 0\n",
      "20093 ISHARASSMENT is 0\n",
      "20101 ISHARASSMENT is 0\n",
      "20120 ISHARASSMENT is 0\n",
      "20194 ISHARASSMENT is 0\n",
      "20216 ISHARASSMENT is 1\n",
      "20219 ISHARASSMENT is 0\n",
      "20290 ISHARASSMENT is 0\n",
      "20337 ISHARASSMENT is 0\n",
      "20347 ISHARASSMENT is 0\n",
      "20425 ISHARASSMENT is 0\n",
      "20456 ISHARASSMENT is 0\n",
      "20706 ISHARASSMENT is 0\n",
      "20713 ISHARASSMENT is 0\n",
      "20820 ISHARASSMENT is 0\n",
      "20853 ISHARASSMENT is 0\n",
      "20886 ISHARASSMENT is 0\n",
      "20897 ISHARASSMENT is 1\n",
      "20975 ISHARASSMENT is 1\n",
      "21016 ISHARASSMENT is 1\n",
      "21149 ISHARASSMENT is 0\n",
      "21202 ISHARASSMENT is 0\n",
      "21210 ISHARASSMENT is 0\n",
      "21290 ISHARASSMENT is 0\n",
      "21318 ISHARASSMENT is 0\n",
      "21355 ISHARASSMENT is 0\n",
      "21440 ISHARASSMENT is 0\n",
      "21492 ISHARASSMENT is 0\n",
      "21632 ISHARASSMENT is 0\n",
      "21685 ISHARASSMENT is 0\n",
      "21781 ISHARASSMENT is 1\n",
      "21783 ISHARASSMENT is 0\n",
      "21791 ISHARASSMENT is 0\n",
      "21802 ISHARASSMENT is 0\n",
      "21806 ISHARASSMENT is 0\n",
      "21823 ISHARASSMENT is 1\n",
      "21846 ISHARASSMENT is 0\n",
      "21885 ISHARASSMENT is 0\n",
      "21934 ISHARASSMENT is 0\n",
      "21990 ISHARASSMENT is 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_labels(df):\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if math.isnan(df.iloc[i].ISHARASSMENT):\n",
    "            labels.append(int(df.iloc[i].AUTO_ISHARASSMENT))\n",
    "        else:\n",
    "            labels.append(int(df.iloc[i].ISHARASSMENT))\n",
    "            print(i, \"ISHARASSMENT is\", int(df.iloc[i].ISHARASSMENT))\n",
    "    return labels\n",
    "labels = get_labels(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_as_list = pd_data[\"TWEET\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        pd_data, \n",
    "        np.asarray(labels),\n",
    "        train_size=0.66, \n",
    "        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>ISTYPEHOMOSEXUAL</th>\n",
       "      <th>ISTYPETRANSGENDER</th>\n",
       "      <th>ISTYPEBISEXUAL</th>\n",
       "      <th>HASPRONOUNS</th>\n",
       "      <th>ISHARASSMENT</th>\n",
       "      <th>AUTO_ISHARASSMENT</th>\n",
       "      <th>PASTEXPERIENCE</th>\n",
       "      <th>AUTO_PASTEXPERIENCE</th>\n",
       "      <th>CLEAN_TWEET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>1373759723900604418</td>\n",
       "      <td>1106283738239885312</td>\n",
       "      <td>yall i drove myself home today iâ€™m beating the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>yall i drove myself home today im beating the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21271</th>\n",
       "      <td>1382814325899989002</td>\n",
       "      <td>1206123732802134016</td>\n",
       "      <td>@cayon4299454775 @i_destroy_Fags @BootlegChanc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>canyon idestroyfags bootlegchancla brioniago i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11036</th>\n",
       "      <td>1375008807034753026</td>\n",
       "      <td>1342187600627556352</td>\n",
       "      <td>retweet and follow to win with me on my twitte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>retweet and follow to win with me on my twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20520</th>\n",
       "      <td>1382406785789784065</td>\n",
       "      <td>1045717980364099584</td>\n",
       "      <td>@fag_femdom @Visa @Mastercard Maybe they need ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>fagfemdom visa mastercard maybe they need to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250</th>\n",
       "      <td>1374974266085535744</td>\n",
       "      <td>813528827607584772</td>\n",
       "      <td>suck my dick and call me a faggot</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>suck my dick and call me a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>1371610522588745731</td>\n",
       "      <td>807750294</td>\n",
       "      <td>@brexitblog_info @PatWilliams1944 @IainDale @B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>brexitbloginfo patwilliams andale barrier unfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16523</th>\n",
       "      <td>1376960820433846272</td>\n",
       "      <td>1244013545320316930</td>\n",
       "      <td>@LemonLimeFrog ty bby appreciate it &amp;lt;3 /gen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>lemonlimefrog ty by appreciate it it gen is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>1374095716969295880</td>\n",
       "      <td>1346880669033635845</td>\n",
       "      <td>@Femboy_AgeRe I think thatâ€™s kinda like gays a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>femboyagere i think thats kinda like gays and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15653</th>\n",
       "      <td>1377027211451043842</td>\n",
       "      <td>1148841399472840705</td>\n",
       "      <td>If you a dyke just say that https://t.co/BCvf7...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>if you a dyke just say that httpstcobcvfbugiy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13505</th>\n",
       "      <td>1376255096670072841</td>\n",
       "      <td>1316932245169557504</td>\n",
       "      <td>@RonTryhard @LordXav1er @The_OmegaX @saintjame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>rontryhard lordxaver theomegax saintjamesx fra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7480 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TWEETID               USERID  \\\n",
       "5767   1373759723900604418  1106283738239885312   \n",
       "21271  1382814325899989002  1206123732802134016   \n",
       "11036  1375008807034753026  1342187600627556352   \n",
       "20520  1382406785789784065  1045717980364099584   \n",
       "11250  1374974266085535744   813528827607584772   \n",
       "...                    ...                  ...   \n",
       "2924   1371610522588745731            807750294   \n",
       "16523  1376960820433846272  1244013545320316930   \n",
       "6530   1374095716969295880  1346880669033635845   \n",
       "15653  1377027211451043842  1148841399472840705   \n",
       "13505  1376255096670072841  1316932245169557504   \n",
       "\n",
       "                                                   TWEET  ISTYPEHOMOSEXUAL  \\\n",
       "5767   yall i drove myself home today iâ€™m beating the...                 1   \n",
       "21271  @cayon4299454775 @i_destroy_Fags @BootlegChanc...                 0   \n",
       "11036  retweet and follow to win with me on my twitte...                 0   \n",
       "20520  @fag_femdom @Visa @Mastercard Maybe they need ...                 1   \n",
       "11250                  suck my dick and call me a faggot                 1   \n",
       "...                                                  ...               ...   \n",
       "2924   @brexitblog_info @PatWilliams1944 @IainDale @B...                 1   \n",
       "16523  @LemonLimeFrog ty bby appreciate it &lt;3 /gen...                 0   \n",
       "6530   @Femboy_AgeRe I think thatâ€™s kinda like gays a...                 1   \n",
       "15653  If you a dyke just say that https://t.co/BCvf7...                 1   \n",
       "13505  @RonTryhard @LordXav1er @The_OmegaX @saintjame...                 1   \n",
       "\n",
       "       ISTYPETRANSGENDER  ISTYPEBISEXUAL  HASPRONOUNS  ISHARASSMENT  \\\n",
       "5767                   0               0          0.0           NaN   \n",
       "21271                  0               0          0.0           NaN   \n",
       "11036                  0               0          0.0           NaN   \n",
       "20520                  0               0          0.0           NaN   \n",
       "11250                  0               0          0.0           NaN   \n",
       "...                  ...             ...          ...           ...   \n",
       "2924                   0               0          0.0           NaN   \n",
       "16523                  0               0          1.0           NaN   \n",
       "6530                   0               0          0.0           NaN   \n",
       "15653                  0               0          0.0           NaN   \n",
       "13505                  0               0          0.0           NaN   \n",
       "\n",
       "       AUTO_ISHARASSMENT  PASTEXPERIENCE AUTO_PASTEXPERIENCE  \\\n",
       "5767                 1.0             NaN                None   \n",
       "21271                0.0             NaN                None   \n",
       "11036                0.0             NaN                None   \n",
       "20520                0.0             NaN                None   \n",
       "11250                0.0             NaN                None   \n",
       "...                  ...             ...                 ...   \n",
       "2924                 0.0             NaN                None   \n",
       "16523                0.0             NaN                None   \n",
       "6530                 1.0             NaN                None   \n",
       "15653                1.0             NaN                None   \n",
       "13505                0.0             NaN                None   \n",
       "\n",
       "                                             CLEAN_TWEET  \n",
       "5767   yall i drove myself home today im beating the ...  \n",
       "21271  canyon idestroyfags bootlegchancla brioniago i...  \n",
       "11036  retweet and follow to win with me on my twitte...  \n",
       "20520  fagfemdom visa mastercard maybe they need to t...  \n",
       "11250                  suck my dick and call me a faggot  \n",
       "...                                                  ...  \n",
       "2924   brexitbloginfo patwilliams andale barrier unfo...  \n",
       "16523  lemonlimefrog ty by appreciate it it gen is re...  \n",
       "6530   femboyagere i think thats kinda like gays and ...  \n",
       "15653      if you a dyke just say that httpstcobcvfbugiy  \n",
       "13505  rontryhard lordxaver theomegax saintjamesx fra...  \n",
       "\n",
       "[7480 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 'CLEAN' tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  32556\n",
      "Accuracy of classifier:  0.9106951871657754\n",
      "\n",
      "confusion matrix: \n",
      " [[5992  191]\n",
      " [ 477  820]]\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      6183\n",
      "           1       0.81      0.63      0.71      1297\n",
      "\n",
      "    accuracy                           0.91      7480\n",
      "   macro avg       0.87      0.80      0.83      7480\n",
      "weighted avg       0.91      0.91      0.91      7480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_model = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "#Instantiate vectorizer to generate features from text input\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train.CLEAN_TWEET)\n",
    "num_features = len(vectorizer.get_feature_names())\n",
    "print(\"Number of features: \", num_features)\n",
    "#Generate feature set for train and test data\n",
    "train_tfidf = vectorizer.transform(X_train.CLEAN_TWEET)\n",
    "test_tfidf =  vectorizer.transform(X_test.CLEAN_TWEET)\n",
    "\n",
    "#Generate model and fit to training features\n",
    "log_model = log_model.fit(X=train_tfidf, y=y_train)\n",
    "\n",
    "#Generate predictions on test features\n",
    "y_pred = log_model.predict(test_tfidf)\n",
    "\n",
    "#Generate accuracy score of predictions on our test dataset\n",
    "print(\"Accuracy of classifier: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Generate confusion matrix for performance analysis on our test dataset\n",
    "print(\"\\nconfusion matrix: \\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "\n",
    "#Generate classification report for performance analysis on our test dataset\n",
    "print(\"\\nclassification report: \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train on Original, non preprocessed, Tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  35243\n",
      "Accuracy of classifier:  0.9127005347593583\n",
      "\n",
      "confusion matrix: \n",
      " [[5983  200]\n",
      " [ 453  844]]\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      6183\n",
      "           1       0.81      0.65      0.72      1297\n",
      "\n",
      "    accuracy                           0.91      7480\n",
      "   macro avg       0.87      0.81      0.83      7480\n",
      "weighted avg       0.91      0.91      0.91      7480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "#Instantiate vectorizer to generate features from text input\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train.TWEET)\n",
    "num_features = len(vectorizer.get_feature_names())\n",
    "print(\"Number of features: \", num_features)\n",
    "#Generate feature set for train and test data\n",
    "train_tfidf = vectorizer.transform(X_train.TWEET)\n",
    "test_tfidf =  vectorizer.transform(X_test.TWEET)\n",
    "\n",
    "#Generate model and fit to training features\n",
    "log_model = log_model.fit(X=train_tfidf, y=y_train)\n",
    "\n",
    "#Generate predictions on test features\n",
    "y_pred = log_model.predict(test_tfidf)\n",
    "\n",
    "#Generate accuracy score of predictions on our test dataset\n",
    "print(\"Accuracy of classifier: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Generate confusion matrix for performance analysis on our test dataset\n",
    "print(\"\\nconfusion matrix: \\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "\n",
    "#Generate classification report for performance analysis on our test dataset\n",
    "print(\"\\nclassification report: \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SGDClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "svm_clf.fit(X_train.TWEET, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "naive_clf.fit(X_train.TWEET, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine classifier:\t 0.9181818181818182\n",
      "Accuracy of Naive Bayes classifier:\t\t 0.8334224598930481\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Support Vector Machine classifier:\\t\",np.mean(svm_pred == y_test))\n",
    "naive_pred = naive_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Naive Bayes classifier:\\t\\t\",np.mean(naive_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "classification report for Support Vector Machine classifer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      6183\n",
      "           1       0.80      0.71      0.75      1297\n",
      "\n",
      "    accuracy                           0.92      7480\n",
      "   macro avg       0.87      0.83      0.85      7480\n",
      "weighted avg       0.92      0.92      0.92      7480\n",
      "\n",
      "confusion matrix for Support Vector Machine classifier\n",
      " [[5952  231]\n",
      " [ 381  916]]\n",
      "\n",
      "\n",
      "classification report for Naive Bayes classifier\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      6183\n",
      "           1       0.98      0.04      0.08      1297\n",
      "\n",
      "    accuracy                           0.83      7480\n",
      "   macro avg       0.91      0.52      0.49      7480\n",
      "weighted avg       0.86      0.83      0.76      7480\n",
      "\n",
      "confusion matrix for Naive Bayes classifier\n",
      " [[6182    1]\n",
      " [1245   52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\n\\nclassification report for Support Vector Machine classifer\\n\", metrics.classification_report(y_test, svm_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Support Vector Machine classifier\\n\",metrics.confusion_matrix(y_test, svm_pred))\n",
    "\n",
    "print(\"\\n\\nclassification report for Naive Bayes classifier\\n\", metrics.classification_report(y_test, naive_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Naive Bayes classifier\\n\",metrics.confusion_matrix(y_test, naive_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network classifier:\t\t 0.8986631016042781\n",
      "\n",
      "\n",
      "classification report for Neural Network classifier\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      6183\n",
      "           1       0.73      0.67      0.70      1297\n",
      "\n",
      "    accuracy                           0.90      7480\n",
      "   macro avg       0.83      0.81      0.82      7480\n",
      "weighted avg       0.90      0.90      0.90      7480\n",
      "\n",
      "confusion matrix for Neural Network classifier\n",
      " [[5854  329]\n",
      " [ 429  868]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "neural_clf.fit(X_train.TWEET, y_train)\n",
    "neural_pred = neural_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Neural Network classifier:\\t\\t\",np.mean(neural_pred == y_test))\n",
    "print(\"\\n\\nclassification report for Neural Network classifier\\n\", metrics.classification_report(y_test, neural_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Neural Network classifier\\n\",metrics.confusion_matrix(y_test, neural_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC classifier:\t\t 0.9185828877005348\n",
      "\n",
      "\n",
      "classification report for SVC classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      6183\n",
      "           1       0.82      0.68      0.74      1297\n",
      "\n",
      "    accuracy                           0.92      7480\n",
      "   macro avg       0.88      0.82      0.85      7480\n",
      "weighted avg       0.92      0.92      0.92      7480\n",
      "\n",
      "confusion matrix for SVC classifier\n",
      " [[5987  196]\n",
      " [ 413  884]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "svc_clf.fit(X_train.TWEET, y_train)\n",
    "svc_pred = svc_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of SVC classifier:\\t\\t\",np.mean(svc_pred == y_test))\n",
    "print(\"\\n\\nclassification report for SVC classifier:\\n\", metrics.classification_report(y_test, svc_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for SVC classifier\\n\",metrics.confusion_matrix(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier:\t\t 0.8989304812834225\n",
      "\n",
      "\n",
      "classification report for Random Forest classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      6183\n",
      "           1       0.83      0.53      0.64      1297\n",
      "\n",
      "    accuracy                           0.90      7480\n",
      "   macro avg       0.87      0.75      0.79      7480\n",
      "weighted avg       0.89      0.90      0.89      7480\n",
      "\n",
      "confusion matrix for Random Forest classifier\n",
      " [[6042  141]\n",
      " [ 615  682]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "forest_clf.fit(X_train.TWEET, y_train)\n",
    "forest_pred = forest_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Random Forest classifier:\\t\\t\",np.mean(forest_pred == y_test))\n",
    "print(\"\\n\\nclassification report for Random Forest classifier:\\n\", metrics.classification_report(y_test, forest_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Random Forest classifier\\n\",metrics.confusion_matrix(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
