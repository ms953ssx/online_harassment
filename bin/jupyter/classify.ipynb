{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import sqlite3\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Connect to DB\n",
    "conn = sqlite3.connect(\"../../etc/database_store/auto_tweets.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets in DB:  40266\n",
      "Total Manual Labelled tweets in DB:  512\n"
     ]
    }
   ],
   "source": [
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "    #Construct SQL Queries\n",
    "    #Count Total amount of Tweets in Database\n",
    "    cur.execute(\"SELECT COUNT(USERID) FROM TWEETS\")\n",
    "    print(\"Total Tweets in DB: \", cur.fetchall()[0][0])\n",
    "    #Count amount of manually labelled tweets currently in Database\n",
    "    cur.execute(\"SELECT COUNT(USERID) FROM TWEETS WHERE ISHARASSMENT IS NOT NULL\")\n",
    "    print(\"Total Manual Labelled tweets in DB: \", cur.fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain all labelled tweets from DB\n",
    "pd_data = pd.read_sql(con=conn,sql=\"SELECT * FROM TWEETS WHERE AUTO_ISHARASSMENT IS NOT NULL OR ISHARASSMENT IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sample of data to save memory. Using full dataset causes Kernel to crash from memory overflow on 16GB system\n",
    "pd_data = pd_data.sample(n=15000, random_state=70824426)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "    \n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataframe:  8.31 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"size of dataframe: \", convert_size(sys.getsizeof(pd_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>ISTYPEHOMOSEXUAL</th>\n",
       "      <th>ISTYPETRANSGENDER</th>\n",
       "      <th>ISTYPEBISEXUAL</th>\n",
       "      <th>HASPRONOUNS</th>\n",
       "      <th>ISHARASSMENT</th>\n",
       "      <th>AUTO_ISHARASSMENT</th>\n",
       "      <th>PASTEXPERIENCE</th>\n",
       "      <th>AUTO_PASTEXPERIENCE</th>\n",
       "      <th>CLEAN_TWEET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13935</th>\n",
       "      <td>1376217439940251651</td>\n",
       "      <td>1221213601559666688</td>\n",
       "      <td>@ilovebram2 nah kataraâ€™s the best bender i sai...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ilovebram nah katara the best bender i said wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>1374509846347718658</td>\n",
       "      <td>242759164</td>\n",
       "      <td>@BorisJohnson Hey Doris which you want Restaur...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>borisjohnson hey doris which you want restaura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11459</th>\n",
       "      <td>1375428519346380805</td>\n",
       "      <td>1315261675944124416</td>\n",
       "      <td>@Fag_Prince Good morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>fagprince good morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18387</th>\n",
       "      <td>1377751657459589120</td>\n",
       "      <td>1145706546309083136</td>\n",
       "      <td>@fIwrchuu slur // \\n\\nyou called me a fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>fiwrchuu slur you called me a fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>1382479737864396803</td>\n",
       "      <td>773560017945554945</td>\n",
       "      <td>i knew dominic fike was rlly dominic fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>i knew dominic like was rlly dominic fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1365319227964608518</td>\n",
       "      <td>78631784</td>\n",
       "      <td>@elonmusk Totally Batty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>elonmusk totally batty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>1382454058859036674</td>\n",
       "      <td>17742969</td>\n",
       "      <td>@BettyBathory0 i just read this to alice and s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>bettybathory i just read this to alice and she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>1370497145602707458</td>\n",
       "      <td>1366470932601180160</td>\n",
       "      <td>Kill this fag https://t.co/vMGomyFBRY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>kill this fag httpstcovmgomyfbry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>1372679295458451458</td>\n",
       "      <td>1719221334</td>\n",
       "      <td>I was trying to remember how many of my high s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>i was trying to remember how many of my high s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17809</th>\n",
       "      <td>1377332351936557058</td>\n",
       "      <td>6502262</td>\n",
       "      <td>@danbarker @carlhendy True. And I consider my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>debarker carlhendy true and i consider my litt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TWEETID               USERID  \\\n",
       "13935  1376217439940251651  1221213601559666688   \n",
       "7184   1374509846347718658            242759164   \n",
       "11459  1375428519346380805  1315261675944124416   \n",
       "18387  1377751657459589120  1145706546309083136   \n",
       "19575  1382479737864396803   773560017945554945   \n",
       "...                    ...                  ...   \n",
       "152    1365319227964608518             78631784   \n",
       "19852  1382454058859036674             17742969   \n",
       "1759   1370497145602707458  1366470932601180160   \n",
       "4229   1372679295458451458           1719221334   \n",
       "17809  1377332351936557058              6502262   \n",
       "\n",
       "                                                   TWEET  ISTYPEHOMOSEXUAL  \\\n",
       "13935  @ilovebram2 nah kataraâ€™s the best bender i sai...                 1   \n",
       "7184   @BorisJohnson Hey Doris which you want Restaur...                 1   \n",
       "11459                           @Fag_Prince Good morning                 0   \n",
       "18387          @fIwrchuu slur // \\n\\nyou called me a fag                 1   \n",
       "19575           i knew dominic fike was rlly dominic fag                 1   \n",
       "...                                                  ...               ...   \n",
       "152                              @elonmusk Totally Batty                 0   \n",
       "19852  @BettyBathory0 i just read this to alice and s...                 0   \n",
       "1759               Kill this fag https://t.co/vMGomyFBRY                 1   \n",
       "4229   I was trying to remember how many of my high s...                 1   \n",
       "17809  @danbarker @carlhendy True. And I consider my ...                 1   \n",
       "\n",
       "       ISTYPETRANSGENDER  ISTYPEBISEXUAL  HASPRONOUNS  ISHARASSMENT  \\\n",
       "13935                  0               0          0.0           NaN   \n",
       "7184                   0               0          0.0           NaN   \n",
       "11459                  0               0          0.0           NaN   \n",
       "18387                  0               0          0.0           NaN   \n",
       "19575                  0               0          1.0           NaN   \n",
       "...                  ...             ...          ...           ...   \n",
       "152                    0               0          0.0           NaN   \n",
       "19852                  0               0          1.0           NaN   \n",
       "1759                   0               0          0.0           NaN   \n",
       "4229                   0               0          0.0           NaN   \n",
       "17809                  0               0          0.0           NaN   \n",
       "\n",
       "       AUTO_ISHARASSMENT  PASTEXPERIENCE AUTO_PASTEXPERIENCE  \\\n",
       "13935                0.0             NaN                None   \n",
       "7184                 0.0             NaN                None   \n",
       "11459                0.0             NaN                None   \n",
       "18387                0.0             NaN                None   \n",
       "19575                0.0             NaN                None   \n",
       "...                  ...             ...                 ...   \n",
       "152                  0.0             NaN                None   \n",
       "19852                0.0             NaN                None   \n",
       "1759                 1.0             NaN                None   \n",
       "4229                 0.0             NaN                None   \n",
       "17809                0.0             NaN                None   \n",
       "\n",
       "                                             CLEAN_TWEET  \n",
       "13935  ilovebram nah katara the best bender i said wh...  \n",
       "7184   borisjohnson hey doris which you want restaura...  \n",
       "11459                             fagprince good morning  \n",
       "18387                  fiwrchuu slur you called me a fag  \n",
       "19575           i knew dominic like was rlly dominic fag  \n",
       "...                                                  ...  \n",
       "152                               elonmusk totally batty  \n",
       "19852  bettybathory i just read this to alice and she...  \n",
       "1759                    kill this fag httpstcovmgomyfbry  \n",
       "4229   i was trying to remember how many of my high s...  \n",
       "17809  debarker carlhendy true and i consider my litt...  \n",
       "\n",
       "[15000 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 ISHARASSMENT is 0\n",
      "35 ISHARASSMENT is 1\n",
      "36 ISHARASSMENT is 0\n",
      "97 ISHARASSMENT is 0\n",
      "144 ISHARASSMENT is 0\n",
      "193 ISHARASSMENT is 0\n",
      "222 ISHARASSMENT is 1\n",
      "240 ISHARASSMENT is 0\n",
      "299 ISHARASSMENT is 0\n",
      "316 ISHARASSMENT is 0\n",
      "375 ISHARASSMENT is 0\n",
      "399 ISHARASSMENT is 0\n",
      "436 ISHARASSMENT is 0\n",
      "477 ISHARASSMENT is 0\n",
      "584 ISHARASSMENT is 1\n",
      "638 ISHARASSMENT is 0\n",
      "685 ISHARASSMENT is 0\n",
      "746 ISHARASSMENT is 1\n",
      "756 ISHARASSMENT is 0\n",
      "777 ISHARASSMENT is 1\n",
      "815 ISHARASSMENT is 0\n",
      "855 ISHARASSMENT is 0\n",
      "872 ISHARASSMENT is 1\n",
      "908 ISHARASSMENT is 0\n",
      "925 ISHARASSMENT is 0\n",
      "927 ISHARASSMENT is 0\n",
      "955 ISHARASSMENT is 0\n",
      "1116 ISHARASSMENT is 0\n",
      "1130 ISHARASSMENT is 1\n",
      "1135 ISHARASSMENT is 0\n",
      "1184 ISHARASSMENT is 0\n",
      "1212 ISHARASSMENT is 0\n",
      "1219 ISHARASSMENT is 0\n",
      "1221 ISHARASSMENT is 1\n",
      "1252 ISHARASSMENT is 1\n",
      "1338 ISHARASSMENT is 0\n",
      "1352 ISHARASSMENT is 0\n",
      "1424 ISHARASSMENT is 1\n",
      "1531 ISHARASSMENT is 0\n",
      "1582 ISHARASSMENT is 1\n",
      "1613 ISHARASSMENT is 0\n",
      "1750 ISHARASSMENT is 0\n",
      "1761 ISHARASSMENT is 0\n",
      "1825 ISHARASSMENT is 0\n",
      "1837 ISHARASSMENT is 0\n",
      "2023 ISHARASSMENT is 0\n",
      "2059 ISHARASSMENT is 0\n",
      "2114 ISHARASSMENT is 0\n",
      "2180 ISHARASSMENT is 0\n",
      "2193 ISHARASSMENT is 0\n",
      "2249 ISHARASSMENT is 0\n",
      "2403 ISHARASSMENT is 1\n",
      "2417 ISHARASSMENT is 0\n",
      "2431 ISHARASSMENT is 1\n",
      "2485 ISHARASSMENT is 0\n",
      "2559 ISHARASSMENT is 0\n",
      "2570 ISHARASSMENT is 0\n",
      "2592 ISHARASSMENT is 1\n",
      "2704 ISHARASSMENT is 1\n",
      "2750 ISHARASSMENT is 0\n",
      "2806 ISHARASSMENT is 0\n",
      "2826 ISHARASSMENT is 0\n",
      "2866 ISHARASSMENT is 0\n",
      "2874 ISHARASSMENT is 0\n",
      "2918 ISHARASSMENT is 0\n",
      "2940 ISHARASSMENT is 1\n",
      "2945 ISHARASSMENT is 0\n",
      "3053 ISHARASSMENT is 0\n",
      "3116 ISHARASSMENT is 0\n",
      "3126 ISHARASSMENT is 0\n",
      "3142 ISHARASSMENT is 0\n",
      "3157 ISHARASSMENT is 1\n",
      "3159 ISHARASSMENT is 0\n",
      "3206 ISHARASSMENT is 1\n",
      "3225 ISHARASSMENT is 1\n",
      "3247 ISHARASSMENT is 0\n",
      "3264 ISHARASSMENT is 0\n",
      "3282 ISHARASSMENT is 0\n",
      "3285 ISHARASSMENT is 0\n",
      "3347 ISHARASSMENT is 0\n",
      "3361 ISHARASSMENT is 1\n",
      "3383 ISHARASSMENT is 0\n",
      "3458 ISHARASSMENT is 0\n",
      "3524 ISHARASSMENT is 0\n",
      "3562 ISHARASSMENT is 1\n",
      "3609 ISHARASSMENT is 0\n",
      "3619 ISHARASSMENT is 0\n",
      "3647 ISHARASSMENT is 1\n",
      "3668 ISHARASSMENT is 0\n",
      "3796 ISHARASSMENT is 0\n",
      "3824 ISHARASSMENT is 0\n",
      "3873 ISHARASSMENT is 0\n",
      "3886 ISHARASSMENT is 0\n",
      "3902 ISHARASSMENT is 0\n",
      "3912 ISHARASSMENT is 0\n",
      "3937 ISHARASSMENT is 0\n",
      "3989 ISHARASSMENT is 0\n",
      "3990 ISHARASSMENT is 0\n",
      "4050 ISHARASSMENT is 0\n",
      "4136 ISHARASSMENT is 0\n",
      "4157 ISHARASSMENT is 0\n",
      "4168 ISHARASSMENT is 0\n",
      "4286 ISHARASSMENT is 1\n",
      "4376 ISHARASSMENT is 0\n",
      "4441 ISHARASSMENT is 0\n",
      "4475 ISHARASSMENT is 0\n",
      "4525 ISHARASSMENT is 0\n",
      "4539 ISHARASSMENT is 1\n",
      "4547 ISHARASSMENT is 0\n",
      "4602 ISHARASSMENT is 0\n",
      "4628 ISHARASSMENT is 0\n",
      "4652 ISHARASSMENT is 0\n",
      "4659 ISHARASSMENT is 0\n",
      "4732 ISHARASSMENT is 0\n",
      "4758 ISHARASSMENT is 0\n",
      "4792 ISHARASSMENT is 0\n",
      "4803 ISHARASSMENT is 1\n",
      "4848 ISHARASSMENT is 0\n",
      "4936 ISHARASSMENT is 1\n",
      "4939 ISHARASSMENT is 0\n",
      "4993 ISHARASSMENT is 0\n",
      "4999 ISHARASSMENT is 0\n",
      "5079 ISHARASSMENT is 0\n",
      "5229 ISHARASSMENT is 0\n",
      "5251 ISHARASSMENT is 1\n",
      "5253 ISHARASSMENT is 0\n",
      "5348 ISHARASSMENT is 1\n",
      "5379 ISHARASSMENT is 0\n",
      "5431 ISHARASSMENT is 1\n",
      "5765 ISHARASSMENT is 0\n",
      "5807 ISHARASSMENT is 1\n",
      "5852 ISHARASSMENT is 0\n",
      "5887 ISHARASSMENT is 0\n",
      "5890 ISHARASSMENT is 0\n",
      "5950 ISHARASSMENT is 0\n",
      "5983 ISHARASSMENT is 0\n",
      "6102 ISHARASSMENT is 1\n",
      "6173 ISHARASSMENT is 0\n",
      "6194 ISHARASSMENT is 1\n",
      "6406 ISHARASSMENT is 0\n",
      "6512 ISHARASSMENT is 0\n",
      "6602 ISHARASSMENT is 0\n",
      "6628 ISHARASSMENT is 1\n",
      "6681 ISHARASSMENT is 0\n",
      "6717 ISHARASSMENT is 0\n",
      "6739 ISHARASSMENT is 0\n",
      "6740 ISHARASSMENT is 0\n",
      "6848 ISHARASSMENT is 0\n",
      "6921 ISHARASSMENT is 0\n",
      "6927 ISHARASSMENT is 0\n",
      "6935 ISHARASSMENT is 0\n",
      "6997 ISHARASSMENT is 0\n",
      "7052 ISHARASSMENT is 0\n",
      "7139 ISHARASSMENT is 0\n",
      "7185 ISHARASSMENT is 0\n",
      "7209 ISHARASSMENT is 1\n",
      "7265 ISHARASSMENT is 0\n",
      "7339 ISHARASSMENT is 1\n",
      "7354 ISHARASSMENT is 0\n",
      "7363 ISHARASSMENT is 0\n",
      "7383 ISHARASSMENT is 0\n",
      "7500 ISHARASSMENT is 0\n",
      "7554 ISHARASSMENT is 0\n",
      "7566 ISHARASSMENT is 0\n",
      "7570 ISHARASSMENT is 0\n",
      "7642 ISHARASSMENT is 0\n",
      "7662 ISHARASSMENT is 0\n",
      "7679 ISHARASSMENT is 0\n",
      "7713 ISHARASSMENT is 0\n",
      "7720 ISHARASSMENT is 0\n",
      "7751 ISHARASSMENT is 0\n",
      "7756 ISHARASSMENT is 0\n",
      "7773 ISHARASSMENT is 0\n",
      "7817 ISHARASSMENT is 0\n",
      "7902 ISHARASSMENT is 0\n",
      "7926 ISHARASSMENT is 0\n",
      "8039 ISHARASSMENT is 0\n",
      "8075 ISHARASSMENT is 1\n",
      "8078 ISHARASSMENT is 0\n",
      "8087 ISHARASSMENT is 0\n",
      "8137 ISHARASSMENT is 0\n",
      "8147 ISHARASSMENT is 0\n",
      "8170 ISHARASSMENT is 1\n",
      "8221 ISHARASSMENT is 0\n",
      "8237 ISHARASSMENT is 0\n",
      "8262 ISHARASSMENT is 0\n",
      "8269 ISHARASSMENT is 0\n",
      "8340 ISHARASSMENT is 0\n",
      "8464 ISHARASSMENT is 0\n",
      "8563 ISHARASSMENT is 0\n",
      "8611 ISHARASSMENT is 0\n",
      "8724 ISHARASSMENT is 0\n",
      "8732 ISHARASSMENT is 0\n",
      "8739 ISHARASSMENT is 0\n",
      "8748 ISHARASSMENT is 0\n",
      "8764 ISHARASSMENT is 0\n",
      "8785 ISHARASSMENT is 0\n",
      "8799 ISHARASSMENT is 0\n",
      "8864 ISHARASSMENT is 0\n",
      "8919 ISHARASSMENT is 1\n",
      "8954 ISHARASSMENT is 0\n",
      "8957 ISHARASSMENT is 0\n",
      "9055 ISHARASSMENT is 0\n",
      "9101 ISHARASSMENT is 0\n",
      "9148 ISHARASSMENT is 0\n",
      "9219 ISHARASSMENT is 0\n",
      "9233 ISHARASSMENT is 0\n",
      "9291 ISHARASSMENT is 1\n",
      "9470 ISHARASSMENT is 0\n",
      "9518 ISHARASSMENT is 0\n",
      "9528 ISHARASSMENT is 0\n",
      "9581 ISHARASSMENT is 1\n",
      "9591 ISHARASSMENT is 1\n",
      "9608 ISHARASSMENT is 0\n",
      "9616 ISHARASSMENT is 0\n",
      "9677 ISHARASSMENT is 1\n",
      "9762 ISHARASSMENT is 1\n",
      "9874 ISHARASSMENT is 1\n",
      "9914 ISHARASSMENT is 1\n",
      "9927 ISHARASSMENT is 0\n",
      "10099 ISHARASSMENT is 0\n",
      "10105 ISHARASSMENT is 0\n",
      "10139 ISHARASSMENT is 0\n",
      "10255 ISHARASSMENT is 0\n",
      "10284 ISHARASSMENT is 0\n",
      "10340 ISHARASSMENT is 1\n",
      "10342 ISHARASSMENT is 1\n",
      "10417 ISHARASSMENT is 1\n",
      "10421 ISHARASSMENT is 0\n",
      "10492 ISHARASSMENT is 0\n",
      "10513 ISHARASSMENT is 0\n",
      "10616 ISHARASSMENT is 0\n",
      "10639 ISHARASSMENT is 0\n",
      "10679 ISHARASSMENT is 0\n",
      "10842 ISHARASSMENT is 0\n",
      "10863 ISHARASSMENT is 0\n",
      "10866 ISHARASSMENT is 0\n",
      "10876 ISHARASSMENT is 0\n",
      "10967 ISHARASSMENT is 0\n",
      "10974 ISHARASSMENT is 1\n",
      "10991 ISHARASSMENT is 0\n",
      "11014 ISHARASSMENT is 0\n",
      "11091 ISHARASSMENT is 0\n",
      "11175 ISHARASSMENT is 0\n",
      "11230 ISHARASSMENT is 0\n",
      "11280 ISHARASSMENT is 0\n",
      "11289 ISHARASSMENT is 0\n",
      "11337 ISHARASSMENT is 0\n",
      "11350 ISHARASSMENT is 0\n",
      "11479 ISHARASSMENT is 0\n",
      "11500 ISHARASSMENT is 1\n",
      "11649 ISHARASSMENT is 0\n",
      "11652 ISHARASSMENT is 1\n",
      "11670 ISHARASSMENT is 1\n",
      "11693 ISHARASSMENT is 0\n",
      "11710 ISHARASSMENT is 0\n",
      "11711 ISHARASSMENT is 0\n",
      "11714 ISHARASSMENT is 0\n",
      "11782 ISHARASSMENT is 1\n",
      "11801 ISHARASSMENT is 0\n",
      "11824 ISHARASSMENT is 0\n",
      "11830 ISHARASSMENT is 1\n",
      "11901 ISHARASSMENT is 0\n",
      "11914 ISHARASSMENT is 0\n",
      "11945 ISHARASSMENT is 0\n",
      "11954 ISHARASSMENT is 0\n",
      "11958 ISHARASSMENT is 0\n",
      "11960 ISHARASSMENT is 0\n",
      "11961 ISHARASSMENT is 1\n",
      "11962 ISHARASSMENT is 0\n",
      "12016 ISHARASSMENT is 0\n",
      "12055 ISHARASSMENT is 1\n",
      "12076 ISHARASSMENT is 1\n",
      "12161 ISHARASSMENT is 1\n",
      "12166 ISHARASSMENT is 0\n",
      "12190 ISHARASSMENT is 0\n",
      "12201 ISHARASSMENT is 0\n",
      "12214 ISHARASSMENT is 0\n",
      "12316 ISHARASSMENT is 0\n",
      "12321 ISHARASSMENT is 0\n",
      "12328 ISHARASSMENT is 0\n",
      "12401 ISHARASSMENT is 1\n",
      "12408 ISHARASSMENT is 0\n",
      "12471 ISHARASSMENT is 0\n",
      "12517 ISHARASSMENT is 0\n",
      "12546 ISHARASSMENT is 1\n",
      "12548 ISHARASSMENT is 0\n",
      "12632 ISHARASSMENT is 0\n",
      "12660 ISHARASSMENT is 0\n",
      "12674 ISHARASSMENT is 1\n",
      "12680 ISHARASSMENT is 0\n",
      "12746 ISHARASSMENT is 1\n",
      "12781 ISHARASSMENT is 0\n",
      "12850 ISHARASSMENT is 0\n",
      "12894 ISHARASSMENT is 1\n",
      "12921 ISHARASSMENT is 0\n",
      "12990 ISHARASSMENT is 0\n",
      "13134 ISHARASSMENT is 1\n",
      "13137 ISHARASSMENT is 1\n",
      "13157 ISHARASSMENT is 0\n",
      "13266 ISHARASSMENT is 1\n",
      "13290 ISHARASSMENT is 0\n",
      "13377 ISHARASSMENT is 0\n",
      "13385 ISHARASSMENT is 0\n",
      "13397 ISHARASSMENT is 1\n",
      "13402 ISHARASSMENT is 0\n",
      "13449 ISHARASSMENT is 1\n",
      "13463 ISHARASSMENT is 0\n",
      "13466 ISHARASSMENT is 0\n",
      "13491 ISHARASSMENT is 1\n",
      "13522 ISHARASSMENT is 0\n",
      "13587 ISHARASSMENT is 0\n",
      "13657 ISHARASSMENT is 0\n",
      "13665 ISHARASSMENT is 1\n",
      "13713 ISHARASSMENT is 0\n",
      "13777 ISHARASSMENT is 0\n",
      "13830 ISHARASSMENT is 0\n",
      "13846 ISHARASSMENT is 0\n",
      "13868 ISHARASSMENT is 0\n",
      "13877 ISHARASSMENT is 1\n",
      "13907 ISHARASSMENT is 0\n",
      "13916 ISHARASSMENT is 1\n",
      "13951 ISHARASSMENT is 0\n",
      "14002 ISHARASSMENT is 1\n",
      "14054 ISHARASSMENT is 0\n",
      "14171 ISHARASSMENT is 0\n",
      "14181 ISHARASSMENT is 0\n",
      "14215 ISHARASSMENT is 0\n",
      "14252 ISHARASSMENT is 0\n",
      "14282 ISHARASSMENT is 0\n",
      "14337 ISHARASSMENT is 0\n",
      "14361 ISHARASSMENT is 0\n",
      "14446 ISHARASSMENT is 0\n",
      "14659 ISHARASSMENT is 0\n",
      "14661 ISHARASSMENT is 0\n",
      "14686 ISHARASSMENT is 1\n",
      "14716 ISHARASSMENT is 1\n",
      "14778 ISHARASSMENT is 1\n",
      "14836 ISHARASSMENT is 0\n",
      "14861 ISHARASSMENT is 1\n",
      "14871 ISHARASSMENT is 1\n",
      "14877 ISHARASSMENT is 0\n",
      "14933 ISHARASSMENT is 0\n",
      "14936 ISHARASSMENT is 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_labels(df):\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if math.isnan(df.iloc[i].ISHARASSMENT):\n",
    "            labels.append(int(df.iloc[i].AUTO_ISHARASSMENT))\n",
    "        else:\n",
    "            labels.append(int(df.iloc[i].ISHARASSMENT))\n",
    "            print(i, \"ISHARASSMENT is\", int(df.iloc[i].ISHARASSMENT))\n",
    "    return labels\n",
    "labels = get_labels(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_as_list = pd_data[\"TWEET\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        pd_data, \n",
    "        np.asarray(labels),\n",
    "        train_size=0.66, \n",
    "        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>ISTYPEHOMOSEXUAL</th>\n",
       "      <th>ISTYPETRANSGENDER</th>\n",
       "      <th>ISTYPEBISEXUAL</th>\n",
       "      <th>HASPRONOUNS</th>\n",
       "      <th>ISHARASSMENT</th>\n",
       "      <th>AUTO_ISHARASSMENT</th>\n",
       "      <th>PASTEXPERIENCE</th>\n",
       "      <th>AUTO_PASTEXPERIENCE</th>\n",
       "      <th>CLEAN_TWEET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>1375308376490512386</td>\n",
       "      <td>3245379542</td>\n",
       "      <td>@Fag_Prince I can't really say much about how ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>fagprince i cant really say much about how any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>1374495081533599747</td>\n",
       "      <td>1295478121429426176</td>\n",
       "      <td>@anarcho_fag Yes, exactly. I don't know how yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>anarchofag yes exactly i dont know how you man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15226</th>\n",
       "      <td>1376592792995000321</td>\n",
       "      <td>2557158404</td>\n",
       "      <td>@wavytzi @dumbass__dyke @unh0lypriestess ratio</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>wavytzi dumbassdyke unhlypriestess ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>1374062563072348161</td>\n",
       "      <td>46594586</td>\n",
       "      <td>@MisterSkeezler Did it collapse when you tried...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>misterskeezler did it collapse when you tried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>1375110351604260864</td>\n",
       "      <td>1369049021751427074</td>\n",
       "      <td>@Its_Josias Yeah, that's the Ponce native Mott...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>itsjosias yeah thats the ponce native motto ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1374115662369587208</td>\n",
       "      <td>2265979861</td>\n",
       "      <td>#TeamTatiðŸ’ž\\nLista 1âƒ£ \\n@tatysolcito \\n@teamdin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>teamtatilista tatysolcito teamdinamicas martha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19713</th>\n",
       "      <td>1382466968146567170</td>\n",
       "      <td>1373152052940058627</td>\n",
       "      <td>@moo0_0moo fag\\n\\n(PS just in case I become fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>voodoo fags just in case i become famous and y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20831</th>\n",
       "      <td>1382381723636404227</td>\n",
       "      <td>4742508449</td>\n",
       "      <td>@rutgerFM @NguyenNgocTan04 Agreed, Bender look...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>rutgers nguyenngoctan agreed bender looks good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18544</th>\n",
       "      <td>1377739640061448203</td>\n",
       "      <td>1246449609741938689</td>\n",
       "      <td>@oscahss @fabbgrat sheâ€™ll always be that girl ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>oscar's fatbrat shell always be that girl when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18177</th>\n",
       "      <td>1377766841553199111</td>\n",
       "      <td>1089195222372888576</td>\n",
       "      <td>I have super glue all over my fingers which is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>i have super glue all over my fingers which is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TWEETID               USERID  \\\n",
       "12339  1375308376490512386           3245379542   \n",
       "7397   1374495081533599747  1295478121429426176   \n",
       "15226  1376592792995000321           2557158404   \n",
       "6958   1374062563072348161             46594586   \n",
       "9968   1375110351604260864  1369049021751427074   \n",
       "...                    ...                  ...   \n",
       "6265   1374115662369587208           2265979861   \n",
       "19713  1382466968146567170  1373152052940058627   \n",
       "20831  1382381723636404227           4742508449   \n",
       "18544  1377739640061448203  1246449609741938689   \n",
       "18177  1377766841553199111  1089195222372888576   \n",
       "\n",
       "                                                   TWEET  ISTYPEHOMOSEXUAL  \\\n",
       "12339  @Fag_Prince I can't really say much about how ...                 0   \n",
       "7397   @anarcho_fag Yes, exactly. I don't know how yo...                 1   \n",
       "15226     @wavytzi @dumbass__dyke @unh0lypriestess ratio                 1   \n",
       "6958   @MisterSkeezler Did it collapse when you tried...                 1   \n",
       "9968   @Its_Josias Yeah, that's the Ponce native Mott...                 0   \n",
       "...                                                  ...               ...   \n",
       "6265   #TeamTatiðŸ’ž\\nLista 1âƒ£ \\n@tatysolcito \\n@teamdin...                 0   \n",
       "19713  @moo0_0moo fag\\n\\n(PS just in case I become fa...                 1   \n",
       "20831  @rutgerFM @NguyenNgocTan04 Agreed, Bender look...                 0   \n",
       "18544  @oscahss @fabbgrat sheâ€™ll always be that girl ...                 1   \n",
       "18177  I have super glue all over my fingers which is...                 0   \n",
       "\n",
       "       ISTYPETRANSGENDER  ISTYPEBISEXUAL  HASPRONOUNS  ISHARASSMENT  \\\n",
       "12339                  0               0          0.0           NaN   \n",
       "7397                   0               0          1.0           NaN   \n",
       "15226                  0               0          0.0           NaN   \n",
       "6958                   0               0          0.0           NaN   \n",
       "9968                   0               0          0.0           NaN   \n",
       "...                  ...             ...          ...           ...   \n",
       "6265                   0               0          0.0           NaN   \n",
       "19713                  0               0          1.0           NaN   \n",
       "20831                  0               0          0.0           NaN   \n",
       "18544                  0               0          1.0           NaN   \n",
       "18177                  0               0          1.0           NaN   \n",
       "\n",
       "       AUTO_ISHARASSMENT  PASTEXPERIENCE AUTO_PASTEXPERIENCE  \\\n",
       "12339                0.0             NaN                None   \n",
       "7397                 0.0             NaN                None   \n",
       "15226                0.0             NaN                None   \n",
       "6958                 0.0             NaN                None   \n",
       "9968                 0.0             NaN                None   \n",
       "...                  ...             ...                 ...   \n",
       "6265                 0.0             NaN                None   \n",
       "19713                0.0             NaN                None   \n",
       "20831                0.0             NaN                None   \n",
       "18544                0.0             NaN                None   \n",
       "18177                0.0             NaN                None   \n",
       "\n",
       "                                             CLEAN_TWEET  \n",
       "12339  fagprince i cant really say much about how any...  \n",
       "7397   anarchofag yes exactly i dont know how you man...  \n",
       "15226           wavytzi dumbassdyke unhlypriestess ratio  \n",
       "6958   misterskeezler did it collapse when you tried ...  \n",
       "9968   itsjosias yeah thats the ponce native motto ha...  \n",
       "...                                                  ...  \n",
       "6265   teamtatilista tatysolcito teamdinamicas martha...  \n",
       "19713  voodoo fags just in case i become famous and y...  \n",
       "20831     rutgers nguyenngoctan agreed bender looks good  \n",
       "18544  oscar's fatbrat shell always be that girl when...  \n",
       "18177  i have super glue all over my fingers which is...  \n",
       "\n",
       "[5100 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 'CLEAN' tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  25173\n",
      "Accuracy of classifier:  0.9027450980392157\n",
      "\n",
      "confusion matrix: \n",
      " [[4058  137]\n",
      " [ 359  546]]\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      4195\n",
      "           1       0.80      0.60      0.69       905\n",
      "\n",
      "    accuracy                           0.90      5100\n",
      "   macro avg       0.86      0.79      0.82      5100\n",
      "weighted avg       0.90      0.90      0.90      5100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_model = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "#Instantiate vectorizer to generate features from text input\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train.CLEAN_TWEET)\n",
    "num_features = len(vectorizer.get_feature_names())\n",
    "print(\"Number of features: \", num_features)\n",
    "#Generate feature set for train and test data\n",
    "train_tfidf = vectorizer.transform(X_train.CLEAN_TWEET)\n",
    "test_tfidf =  vectorizer.transform(X_test.CLEAN_TWEET)\n",
    "\n",
    "#Generate model and fit to training features\n",
    "log_model = log_model.fit(X=train_tfidf, y=y_train)\n",
    "\n",
    "#Generate predictions on test features\n",
    "y_pred = log_model.predict(test_tfidf)\n",
    "\n",
    "#Generate accuracy score of predictions on our test dataset\n",
    "print(\"Accuracy of classifier: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Generate confusion matrix for performance analysis on our test dataset\n",
    "print(\"\\nconfusion matrix: \\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "\n",
    "#Generate classification report for performance analysis on our test dataset\n",
    "print(\"\\nclassification report: \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train on Original, non preprocessed, Tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  27121\n",
      "Accuracy of classifier:  0.9035294117647059\n",
      "\n",
      "confusion matrix: \n",
      " [[4055  140]\n",
      " [ 352  553]]\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      4195\n",
      "           1       0.80      0.61      0.69       905\n",
      "\n",
      "    accuracy                           0.90      5100\n",
      "   macro avg       0.86      0.79      0.82      5100\n",
      "weighted avg       0.90      0.90      0.90      5100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "#Instantiate vectorizer to generate features from text input\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train.TWEET)\n",
    "num_features = len(vectorizer.get_feature_names())\n",
    "print(\"Number of features: \", num_features)\n",
    "#Generate feature set for train and test data\n",
    "train_tfidf = vectorizer.transform(X_train.TWEET)\n",
    "test_tfidf =  vectorizer.transform(X_test.TWEET)\n",
    "\n",
    "#Generate model and fit to training features\n",
    "log_model = log_model.fit(X=train_tfidf, y=y_train)\n",
    "\n",
    "#Generate predictions on test features\n",
    "y_pred = log_model.predict(test_tfidf)\n",
    "\n",
    "#Generate accuracy score of predictions on our test dataset\n",
    "print(\"Accuracy of classifier: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Generate confusion matrix for performance analysis on our test dataset\n",
    "print(\"\\nconfusion matrix: \\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "\n",
    "#Generate classification report for performance analysis on our test dataset\n",
    "print(\"\\nclassification report: \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SGDClassifier())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "svm_clf.fit(X_train.TWEET, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "naive_clf.fit(X_train.TWEET, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine classifier:\t 0.9107843137254902\n",
      "Accuracy of Naive Bayes classifier:\t\t 0.8254901960784313\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Support Vector Machine classifier:\\t\",np.mean(svm_pred == y_test))\n",
    "naive_pred = naive_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Naive Bayes classifier:\\t\\t\",np.mean(naive_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "classification report for Support Vector Machine classifer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      4195\n",
      "           1       0.77      0.70      0.74       905\n",
      "\n",
      "    accuracy                           0.91      5100\n",
      "   macro avg       0.86      0.83      0.84      5100\n",
      "weighted avg       0.91      0.91      0.91      5100\n",
      "\n",
      "confusion matrix for Support Vector Machine classifier\n",
      " [[4009  186]\n",
      " [ 269  636]]\n",
      "\n",
      "\n",
      "classification report for Naive Bayes classifier\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90      4195\n",
      "           1       0.94      0.02      0.03       905\n",
      "\n",
      "    accuracy                           0.83      5100\n",
      "   macro avg       0.88      0.51      0.47      5100\n",
      "weighted avg       0.85      0.83      0.75      5100\n",
      "\n",
      "confusion matrix for Naive Bayes classifier\n",
      " [[4194    1]\n",
      " [ 889   16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\n\\nclassification report for Support Vector Machine classifer\\n\", metrics.classification_report(y_test, svm_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Support Vector Machine classifier\\n\",metrics.confusion_matrix(y_test, svm_pred))\n",
    "\n",
    "print(\"\\n\\nclassification report for Naive Bayes classifier\\n\", metrics.classification_report(y_test, naive_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Naive Bayes classifier\\n\",metrics.confusion_matrix(y_test, naive_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network classifier:\t\t 0.8911764705882353\n",
      "\n",
      "\n",
      "classification report for Neural Network classifier\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      4195\n",
      "           1       0.71      0.65      0.68       905\n",
      "\n",
      "    accuracy                           0.89      5100\n",
      "   macro avg       0.82      0.80      0.81      5100\n",
      "weighted avg       0.89      0.89      0.89      5100\n",
      "\n",
      "confusion matrix for Neural Network classifier\n",
      " [[3957  238]\n",
      " [ 317  588]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "neural_clf.fit(X_train.TWEET, y_train)\n",
    "neural_pred = neural_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Neural Network classifier:\\t\\t\",np.mean(neural_pred == y_test))\n",
    "print(\"\\n\\nclassification report for Neural Network classifier\\n\", metrics.classification_report(y_test, neural_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Neural Network classifier\\n\",metrics.confusion_matrix(y_test, neural_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC classifier:\t\t 0.9103921568627451\n",
      "\n",
      "\n",
      "classification report for SVC classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      4195\n",
      "           1       0.81      0.65      0.72       905\n",
      "\n",
      "    accuracy                           0.91      5100\n",
      "   macro avg       0.87      0.81      0.83      5100\n",
      "weighted avg       0.91      0.91      0.91      5100\n",
      "\n",
      "confusion matrix for SVC classifier\n",
      " [[4058  137]\n",
      " [ 320  585]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "svc_clf.fit(X_train.TWEET, y_train)\n",
    "svc_pred = svc_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of SVC classifier:\\t\\t\",np.mean(svc_pred == y_test))\n",
    "print(\"\\n\\nclassification report for SVC classifier:\\n\", metrics.classification_report(y_test, svc_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for SVC classifier\\n\",metrics.confusion_matrix(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier:\t\t 0.8911764705882353\n",
      "\n",
      "\n",
      "classification report for Random Forest classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      4195\n",
      "           1       0.81      0.51      0.62       905\n",
      "\n",
      "    accuracy                           0.89      5100\n",
      "   macro avg       0.85      0.74      0.78      5100\n",
      "weighted avg       0.88      0.89      0.88      5100\n",
      "\n",
      "confusion matrix for Random Forest classifier\n",
      " [[4085  110]\n",
      " [ 445  460]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "forest_clf.fit(X_train.TWEET, y_train)\n",
    "forest_pred = forest_clf.predict(X_test.TWEET)\n",
    "print(\"Accuracy of Random Forest classifier:\\t\\t\",np.mean(forest_pred == y_test))\n",
    "print(\"\\n\\nclassification report for Random Forest classifier:\\n\", metrics.classification_report(y_test, forest_pred, target_names=[\"0\",\"1\"]))\n",
    "print(\"confusion matrix for Random Forest classifier\\n\",metrics.confusion_matrix(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
